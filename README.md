# DeepRead-Agent-Prompt

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Stars](https://img.shields.io/github/stars/li4oya/DeepRead-Agent-Prompt?style=social)](https://github.com/li4oya/DeepRead-Agent-Prompt/stargazers)
[![Issues](https://img.shields.io/github/issues/li4oya/DeepRead-Agent-Prompt)](https://github.com/li4oya/DeepRead-Agent-Prompt/issues)

<p align="center">
  <a href="#-about-the-project">English</a> â€¢
  <a href="#-å…³äºé¡¹ç›®">ç®€ä½“ä¸­æ–‡</a>
</p>

An advanced, multi-agent prompt framework for conducting deep, structured analysis of academic papers. This is not just a summarizer; it's a virtual research team at your command.

ä¸€ä¸ªç”¨äºå¯¹å­¦æœ¯è®ºæ–‡è¿›è¡Œæ·±åº¦ã€ç»“æ„åŒ–åˆ†æçš„é«˜çº§å¤šæ™ºèƒ½ä½“æç¤ºè¯æ¡†æ¶ã€‚è¿™ä¸ä»…æ˜¯ä¸€ä¸ªæ‘˜è¦å·¥å…·ï¼Œæ›´æ˜¯ä¸€ä¸ªå¬ä½ æŒ‡æŒ¥çš„è™šæ‹Ÿç ”ç©¶å›¢é˜Ÿã€‚

---

<details>
<summary><strong>:us: English Readme</strong></summary>

## ğŸš€ About The Project

In the age of information overload, researchers and students are drowning in papers. Traditional "summarize this" prompts provide a superficial overview at best. They often miss the nuances of the methodology, the context of the research, and the true significance of the experimental results.

**DeepRead-Agent-Prompt** solves this problem by simulating a collaborative team of AI specialists. Each "agent" has a distinct roleâ€”from identifying core concepts to meticulously dissecting the methodology and experimental design. The result is a comprehensive, multi-faceted analysis that mirrors the depth you'd expect from a human expert group.

### âœ¨ Key Features

*   **ğŸ§  Multi-Agent Simulation**: Deploys five specialized AI agents for a holistic analysis.
*   **ğŸ”¬ In-Depth Methodological Breakdown**: Goes far beyond summarization to provide a step-by-step deconstruction of the paper's technical approach.
*   **ğŸ“Š Structured Experimental Analysis**: Presents experimental results in a clear "Reason - Result - Figure" format for easy digestion.
*   **ğŸ§© Context-Aware**: Analyzes the paper's background, core scientific questions, and its place within the broader research landscape.
*   **ğŸ¤– Model Agnostic**: Designed to work with any powerful Large Language Model (e.g., GPT-4o, Claude 3 Opus, Gemini 1.5).
*   **ğŸ“– Open & Transparent**: The entire prompt is open-source, allowing for community verification, customization, and improvement.

## ğŸ¤– The Core Prompt

This is the engine that drives the analysis. It's designed to be a single, powerful prompt that you provide to your chosen LLM.

<details>
<summary><strong>Click to view the full Multi-Agent Prompt</strong></summary>

```
Task: In-depth Collaborative Analysis of an Academic Paper
Role Definitions
You will act as a Project Coordinator, responsible for dispatching five AI agents with different specialized abilities to collaboratively complete a comprehensive, in-depth analysis of a research paper. These five agents are:

1. Academic Keyword Extraction Expert
Responsibilities: Identify and extract the 3-5 most central academic domain keywords from the paper's content.

Key Focus: Ensure the accuracy and representativeness of the keywords by synthesizing information from the abstract, main text, and figures.

2. Research Background Analysis Expert
Responsibilities: Conduct a comprehensive analysis of the paper's research background and related work.

Key Focus:

Summarize the current state of the art, challenges, and development trends in the paper's field.

List and analyze related research works, including significant pioneering studies and the latest advancements.

Elucidate the importance, necessity, and innovative contributions of the current study.

Reference the introduction section and relevant data figures.

3. Problem Identification Expert
Responsibilities: Precisely identify and articulate the core scientific problem addressed in the paper.

Key Focus:

Clearly define the core problem the paper aims to solve.

Analyze the significance and research value of this problem.

Identify the limitations and shortcomings of existing methods.

Enhance understanding by referencing illustrative diagrams or comparative figures related to the problem.

4. Methodology Design Analysis Expert
Responsibilities: Provide a deep, step-by-step, multi-level analysis of the methodology proposed in the paper.

Detailed Work Requirements:

4.1 Overall Methodological Architecture Analysis
Overall Design Philosophy: Explain the core idea and design philosophy of the method.

Architectural Component Diagram: Based on the system architecture diagram, detail the functional role of each module.

Data Flow Analysis: Trace the path and transformation of data throughout the entire system.

Differentiation from Existing Methods: Highlight the innovative architectural features of this method.

4.2 Step-by-Step Breakdown of Key Procedures
Provide an in-depth analysis for each key step of the methodology:

Step X: [Step Name]

Objective and Role: What specific problem does this step address, and what is its function within the overall method?

Input-Output Definition: Clearly define the input data format and the resulting output of this step.

Core Algorithmic Mechanism:

Describe the working principle of the algorithm in detail.

Explain the meaning and computational logic of key mathematical formulas.

Analyze the time/space complexity of the algorithm (if mentioned).

Technical Implementation Details:

The specific computational process and processing steps.

The rationale behind key parameter settings and their impact.

Any special data processing techniques or optimization strategies.

Innovation Identification: How does this step improve upon traditional methods?

Corresponding Figure/Table Reference: Clearly cite relevant algorithm flowcharts, formula images, or illustrative diagrams.

4.3 In-depth Interpretation of Key Technologies
Core Algorithm Deep Dive:

The mathematical foundation and theoretical basis of the algorithm.

Analysis of theoretical properties such as convergence, stability, etc.

The scope of applicability and limitations of the algorithm.

Key Data Structures: Important data representation methods and storage strategies.

Optimization Strategy Analysis: Techniques for performance improvement, computational acceleration, etc.

Robustness Design: Mechanisms for handling edge cases and abnormal data.

4.4 Method Integration and Synergy
Inter-Module Interaction: The collaboration mechanisms between different components.

End-to-End Pipeline: The complete processing chain from raw input to final output.

Key Decision Points: Important branches and logical judgments during the method's execution.

5. Experiment Analysis Expert
Responsibilities: Systematically evaluate the paper's experimental design and results analysis.

Key Focus:

Describe the experimental setup in detail (datasets, evaluation metrics, baseline methods, hardware configuration, etc.).

Analyze each experiment in a standardized format, specifically including:

Rationale for Experimental Design: Explain why this experiment was designed and what hypothesis it aims to validate.

Experimental Results: Describe the quantitative and qualitative results in detail.

Corresponding Figures/Tables: Clearly identify the specific figure or table numbers and their content that support the experimental results.

Evaluate the sufficiency, scientific rigor, and persuasiveness of the experiments.

Input Materials
You will receive the following complete paper materials:

Paper Abstract: A summary of the core content.

Paper Main Text: The full text, thoroughly cleaned and pre-processed.

List of Image Resources: High-resolution image paths for each page of the paper, including figures, tables, formulas, algorithm flowcharts, and system architecture diagrams.

Execution Flow
Phase One: Task Distribution and Guidance
Distribute the paper materials (abstract, main text, image resources) to all five specialized agents.

Provide targeted instructions for each agent:

Guide the Keyword Extraction Expert to distill precise keywords using multi-dimensional information.

Guide the Research Background Analysis Expert to deeply investigate related work and the current state of the art.

Guide the Problem Identification Expert to accurately pinpoint the core problem and its significance.

Critically guide the Methodology Design Analysis Expert to leverage image resources for understanding complex technical details and to perform a step-by-step deep dive according to the detailed requirements in sections 4.1-4.4.

Critically guide the Experiment Analysis Expert to analyze the complete logic of each experiment following the standardized format.

Phase Two: Coordination and Integration
Collect and integrate the professional analysis results from all agents to form a structured, comprehensive report.

Final Deliverable
Generate a clearly structured and detailed comprehensive analysis report, strictly organized into the following five sections:

1. Core Keywords
3-5 of the most representative academic keywords.

A brief explanation for each keyword.

2. Research Background and Related Work
Current state and development trends of the research field.

A list of related research works and an analysis of their contributions.

The innovation and importance of the present study.

3. Core Scientific Problem
A clear definition of the problem to be solved.

The importance and challenges of the problem.

The limitations of existing methods.

4. Methodology Design Explained
4.1 Overall Methodological Architecture
Overall Design Philosophy: ...

Analysis of Architectural Components: (Reference Figure X)...

Data Flow: ...

Innovative Architectural Features: ...

4.2 Detailed Analysis of Key Steps
Step 1: [Specific Step Name]

Objective and Role: ...

Input and Output: ...

Core Algorithmic Mechanism:

Working Principle: ...

Interpretation of Mathematical Formulas: ...

Complexity Analysis: ...

Technical Implementation Details:

Specific Computational Process: ...

Parameter Settings: ...

Optimization Strategies: ...

Innovation: ...

Corresponding Figure/Table: Figure X shows...

[Repeat the above format for each key step]

4.3 In-depth Analysis of Core Technologies
4.3.1 Disciplinary Affiliation and Theoretical Foundations
Primary Academic Field: Clearly identify the core discipline to which the paper's method belongs (e.g., Machine Learning, Computer Vision, Natural Language Processing, Signal Processing, Statistics, Mathematical Optimization, Control Theory).

Interdisciplinary Identification: Identify any cross-disciplinary theories involved (e.g., Cognitive Science, Neuroscience, Information Theory, Graph Theory, Game Theory).

Theoretical Lineage:

Mathematical Foundations: Relevant theories from probability, linear algebra, calculus, statistics, topology, etc.

Algorithmic Theory: The theoretical origins of the employed algorithms (e.g., Deep Learning, Reinforcement Learning, Evolutionary Algorithms, Graph Algorithms, Optimization Theory).

Domain-Specific Theory: The core theoretical frameworks and fundamental assumptions of the professional field.

Methodological Genealogy: The method's position in the developmental history of its discipline, its evolutionary relationships, and its theoretical heritage.

4.3.2 Core Algorithm Deep Dive
The mathematical foundation and theoretical basis of the algorithm.

Analysis of theoretical properties such as convergence, stability, etc.

The scope of applicability and limitations of the algorithm.

4.3.3 Key Data Structures and Representations
Important data representation methods and storage strategies.

The theoretical advantages and computational efficiency of the chosen data structures.

4.3.4 Optimization Strategy Analysis
Techniques for performance improvement, computational acceleration, etc.

The theoretical basis and applicable conditions for the optimization strategies.

4.3.5 Robustness Design
Mechanisms for handling edge cases and abnormal data.

The theoretical basis and implementation methods for ensuring stability.

4.4 Method Integration Analysis
Module-Synergy Mechanism: ...

End-to-End Processing Pipeline: ...

Key Decision Logic: ...

5. Experiment Analysis
5.1 Experimental Setup
Dataset Description

Explanation of Evaluation Metrics

Introduction of Baseline Methods

Experimental Platform and Parameter Configuration

5.2 Detailed Experimental Analysis
For each experiment, analyze according to the following three dimensions:

Experiment X: [Experiment Name]

Rationale for Experimental Design: What hypothesis or question is this experiment designed to validate or answer?

Experimental Results: Detailed quantitative data and qualitative analysis.

Corresponding Figure/Table: Clearly label the figure/table number (e.g., Figure X, Table Y) that supports this result.

Quality Requirements
Professionalism: Ensure each section is completed by the corresponding domain expert.

Completeness: Make full use of the provided text and image information.

Accuracy: Pay special attention to the technical details in the methodology and experiment sections.

Depth: The methodology section must provide a step-by-step, in-depth technical analysis.

Standardization: The experiment analysis section must strictly follow the "Rationale-Results-Figure/Table" three-part structure.

Coherence: The report must be clearly structured with a logical flow.

Figure-Text Correlation: Ensure every technical point is clearly supported by and cites a relevant figure or table.

Please begin the in-depth collaborative analysis of the academic paper according to the requirements above.
```

</details>

## ğŸ› ï¸ How to Use

1.  **Copy the Prompt**: Copy the entire core prompt from the section above.
2.  **Prepare Your Materials**:
    *   Convert your target paper (e.g., a PDF) into plain text.
    *   (Optional but Recommended) Note down critical diagrams or formulas with their figure numbers.
3.  **Engage the LLM**:
    *   Open a session with a powerful LLM (e.g., GPT-4o).
    *   Paste the **DeepRead-Agent-Prompt** as your first message.
    *   In the next message, provide the paper's text and any image information.
4.  **Receive the Analysis**: The LLM will generate a detailed, structured report.

## ğŸ’¡ Example Output

Here is a condensed example of the output for the paper *"Respond to Change With Constancy: Instruction-Tuning With LLM for Non-I.I.D. Network Traffic Classification"*.

<details>
<summary><strong>Click to view example analysis</strong></summary>

Here is a comprehensive, in-depth analysis of the research paper, structured as a collaborative report from five specialized AI agents.

1. Core Keywords
Encrypted Traffic Classification: This is the primary task domain. The paper focuses on identifying the category (e.g., application, service, malware) of network traffic even when its content is encrypted and unreadable .

Out-of-Distribution (O.O.D.) Generalization: This is the core challenge the paper addresses. It refers to a model's ability to maintain high performance on test data that follows a different statistical distribution from the training data, a common issue in real-world networks due to factors like application updates and time shifts .

Large Language Models (LLMs): This is the core technology leveraged. The paper adapts the powerful generalization and reasoning capabilities of LLMs, which are typically used for text, to the non-textual domain of network traffic analysis .

Instruction Tuning: This is the key methodological paradigm. Instead of full-scale retraining, the paper uses a lightweight, two-stage tuning process where the LLM is guided with specific instructions to learn traffic graph structures and then adapt to the classification task, enhancing efficiency and O.O.D. performance .

2. Research Background and Related Work
Current State and Development Trends:
The field of network traffic classification is crucial for cybersecurity and network management . However, the widespread adoption of encryption has rendered traditional methods like deep packet inspection (DPI) obsolete . In response, research has shifted towards machine learning-based approaches that analyze content-agnostic data. These are broadly categorized into:

Statistical Feature-based Methods: Using classical machine learning on hand-crafted statistical features (e.g., packet sizes, timings) .

Deep Learning-based Methods: Using neural networks to automatically learn features from raw packet data or sequences .

Pre-training Methods: Applying models like BERT (e.g., ET-BERT) to traffic data to learn general representations, which has shown improved generalization .

Related Research Works and Analysis:
The paper situates its work in the context of several key advancements. Studies like FS-Net and Deeppacket pioneered the use of deep learning on raw traffic sequences. More recent works such as ET-BERT have demonstrated the power of pre-training transformers for this task, achieving strong generalization. Concurrently, methods like GraphDApp and the research on FRG features have highlighted the importance of modeling multi-flow interactions using graph structures to capture more robust patterns.

Innovation and Importance of the Present Study:
The primary innovation of this paper is the novel integration of Large Language Models (LLMs) with a graph-based traffic representation through a self-supervised instruction tuning paradigm. While previous works have struggled with the Independent and Identically Distributed (I.I.D.) assumption , their performance degrades significantly under real-world Out-of-Distribution (O.O.D.) conditions where traffic patterns constantly shift . This study addresses this critical gap by:

Focusing explicitly on O.O.D. generalization, a more realistic and challenging problem.

Leveraging the emergent reasoning and generalization capabilities of LLMs, which have been largely unexplored for this specific problem .

Proposing an efficient instruction-tuning framework (ETooL) that avoids costly retraining, a major limitation of traditional O.O.D. solutions .

Introducing NETD, the first traffic dataset designed specifically to support research on dynamic and controllable distributional shifts .

3. Core Scientific Problem
Problem Definition:
The core scientific problem is the significant performance degradation of encrypted traffic classification models when faced with Out-of-Distribution (O.O.D.) data. This occurs when the statistical distribution of the network traffic changes between the training phase and the deployment (testing) phase, a phenomenon known as "distribution drift" .

Importance and Challenges:
In real-world network environments, distribution drift is inevitable and frequent, caused by factors such as:

Application version updates .

Changes in user behavior over time .

Evolution of network infrastructure and protocols.
This makes models trained under the conventional I.I.D. assumption fragile and unreliable in practice . The challenge is to build a classifier that is robust to these changes and can generalize its knowledge to new, unseen traffic patterns without needing constant access to new labeled data.

Limitations of Existing Methods:
Existing approaches are inadequate for two main reasons :

Feature Instability: Features extracted from single packets or single flows are often not stable enough to withstand distributional shifts .

Insufficient Generalization: Models are typically designed to minimize empirical error on the training distribution and fail to generalize when this distribution changes. The common solutionâ€”periodically retraining the model on newly labeled dataâ€”is expensive, time-consuming, and labor-intensive, as illustrated in Figure 1(a) .

Figure 1 from the paper starkly contrasts the traditional, reactive "Re-Label, Re-Train" cycle with the proposed proactive "Instruction-Tuning" approach, which aims for inherent generalization.

4. Methodology Design Explained
4.1 Overall Methodological Architecture
Overall Design Philosophy:
The core idea of the ETooL framework is to "Respond to Change With Constancy" . It achieves this by learning robust, generic interaction patterns from multi-flow traffic structures and aligning this structural knowledge with the powerful generalization capabilities of an LLM. Instead of learning brittle single-flow patterns, it learns the underlying "grammar" of flow interactions, which is more stable across distributions. The model is then adapted to specific tasks via lightweight instruction tuning, avoiding costly retraining.

Analysis of Architectural Components (Reference Figure 2):
The ETooL framework, shown in Figure 2, consists of three core, sequential components:

Traffic2Graph: This initial module preprocesses raw traffic (PCAP traces) into a structured graph representation. It acts as the "eyes" of the system, transforming unstructured network data into a format that captures multi-flow relationships .

Graph Structural Instruction Tuning: This is the first tuning phase. Its purpose is to teach the LLM to understand the "language" of traffic graphs. It aligns the graph's structural information with the LLM's natural language space using a self-supervised task, injecting domain knowledge without requiring classification labels .

Traffic-Task Instruction Tuning: This is the second and final tuning phase. It adapts the structurally-aware LLM to the specific downstream task of traffic classification. It fine-tunes the model to map the learned graph representations to the correct traffic categories .

Data Flow:
Raw PCAP traffic is first split into session flows. The Traffic2Graph module extracts features (datagrams, packet sizes) and constructs a Traffic Relation Graph (TRG). This graph, along with natural language instructions, is fed into the first tuning stage, Graph Structural Instruction Tuning, which aligns the graph and text modalities. The resulting model, now possessing an understanding of traffic structure, proceeds to the Traffic-Task Instruction Tuning stage. Here, it is fine-tuned on labeled data to perform the final classification task. During inference, the model takes a traffic graph and outputs a classification label.

Innovative Architectural Features:
The key innovation is the two-stage, parameter-frozen instruction tuning process. Unlike traditional fine-tuning, the vast majority of the LLM's parameters remain frozen. Only a small, lightweight projection layer is trained . This makes the process highly efficient and prevents the catastrophic forgetting of knowledge learned during pre-training, which is crucial for generalization.

4.2 Detailed Analysis of Key Steps
Step 1: Traffic2Graph Construction

Objective and Role: To create a discriminative and robust traffic representation by modeling the interaction patterns between multiple network flows. This step transforms raw traffic into a Traffic Relation Graph (TRG) that is less susceptible to single-flow variations and distribution shifts .

Input and Output:

Input: A sequence of network flows from a raw PCAP trace .

Output: A traffic relation graph G=(V,E), where nodes V represent individual flows and edges E represent their relationships .

Core Algorithmic Mechanism:

Working Principle: The process has two sub-steps:

Flow Extractor: For each flow, it extracts key features: the first 128 bytes of the datagram sequence and the directed packet size sequence (+ for client-to-server, - for server-to-client) .

Flow2Graph: It constructs the graph based on two types of relationships between flows: bursting (flows established within a small time threshold, Î³) and adjacency (connecting consecutive BURST structures) .

Technical Implementation Details: The construction process is detailed in Algorithm 1 . Flows are first sorted by their start time. They are then grouped into BURSTs if their start times are within the threshold Î³. Edges are created between concurrent flows within the same BURST (burst edges) and between the last flow of one BURST and the first/last flows of the next (adjacency edges) .

Innovation: This step moves beyond single-flow analysis to explicitly model multi-flow collaborations (BURSTs), capturing a higher-level, more stable representation of application behavior.

Corresponding Figure/Table: Figure 2 (left panel) illustrates the entire Traffic2Graph process, from PCAP to the final graph. Algorithm 1 provides the precise construction logic.

Step 2: Graph Structural Instruction Tuning

Objective and Role: To enable the LLM to understand and interpret the traffic graph structure created in Step 1. This self-supervised phase injects essential domain knowledge about traffic flow topology into the LLM before it attempts any classification task .

Input and Output:

Input: The unlabeled TRG and the raw flow features associated with its nodes.

Output: An LLM whose representations are aligned with the traffic graph's structural information.

Core Algorithmic Mechanism:

Working Principle: This step uses a specially designed self-supervised task called BURST Graph Matching . The model is given a traffic graph structure and a disordered set of the corresponding flow features. Its task is to reorder the features correctly by understanding the topological relationships between the graph nodes .

Interpretation of Mathematical Formulas: Before the matching task, a Traffic Graph Encoding Alignment module aligns the representations from a graph encoder (H) and a flow feature encoder (N) using contrastive learning. Formulas (3) and (4) define the cross-entropy loss function used to pull the representations of matching graph structures and flow features together in the embedding space.

Technical Implementation Details: The parameters of the LLM and the graph encoder are kept frozen. Only a lightweight projection layer is trained to map the graph encodings into the LLM's input space . This makes the tuning process extremely efficient in terms of computation and memory.

Innovation: This is a novel application of self-supervised instruction tuning to the network traffic domain. It cleverly forces the LLM to learn the structural semantics of traffic graphs without needing any expensive labeled data.

Corresponding Figure/Table: Figure 2 (middle panel) provides a high-level illustration of this stage, showing the graph structure and flow features being fed to ETooL for the BURST Graph Matching task.

Step 3: Traffic-Task Instruction Tuning

Objective and Role: To adapt the structurally-aware LLM from Step 2 to the final, supervised task of out-of-distribution encrypted traffic classification .

Input and Output:

Input: Labeled training data, consisting of traffic graphs (X) and their corresponding class labels (y) .

Output: The final ETooL model, fine-tuned to predict traffic labels.

Core Algorithmic Mechanism:

Working Principle: The model is fine-tuned using a standard supervised learning objective (e.g., cross-entropy loss). The instruction template now includes the traffic graph information and a prompt asking for the traffic category.

Interpretation of Mathematical Formulas: Formula (5), y=ETooL(Xâˆ£(Î¸;Ï•)), represents the final inference process where the model predicts the label y given the input traffic graph X and its tuned parameters .

Technical Implementation Details: Crucially, this phase also keeps the full LLM backbone and the graph encoder frozen. It only updates the structure-aware projector inherited from Step 2 and a new, lightweight task-specific classification head . This maintains the efficiency and generalization benefits.

Innovation: The continued use of a parameter-efficient tuning strategy for the downstream task ensures that the model adapts to the new task without compromising the robust, general knowledge learned in the previous stages.

Corresponding Figure/Table: Figure 2 (right panel) depicts this final tuning stage, where the model learns from source distribution data and is then used for inference on data with distribution shifts (e.g., version or time shifts).

4.3 In-depth Analysis of Core Technologies
4.3.1 Disciplinary Affiliation and Theoretical Foundations

Primary Academic Field: Machine Learning, specifically Deep Learning for Network Security.

Interdisciplinary Identification: The methodology integrates concepts from Natural Language Processing (Large Language Models, Instruction Tuning), Graph Theory (Graph Neural Networks, graph construction), and Computer Networks (traffic analysis).

Theoretical Lineage:

Mathematical Foundations: The work relies on principles from linear algebra (vector representations), probability and statistics (distribution shift), and optimization (gradient descent for tuning).

Algorithmic Theory: The core is built upon the Transformer architecture (the foundation of LLMs and ET-BERT), Graph Neural Networks (for encoding graph structures), and Contrastive Learning (for multi-modal alignment).

Methodological Genealogy: ETooL evolves from the lineage of pre-training models like BERT. It represents a shift from general pre-training on token sequences (like ET-BERT) to a more sophisticated, structured, and efficient adaptation method (instruction tuning) that explicitly incorporates domain-specific structural knowledge (traffic graphs).

4.3.2-4.3.5 Core Technologies Deep Dive

Core Algorithm (Instruction Tuning on LLM): The use of Vicuna-7B-v1.5 , an advanced LLM, provides powerful baseline capabilities in pattern recognition and reasoning. The core innovation, parameter-efficient instruction tuning, is critical. By freezing the majority of parameters, it prevents "catastrophic forgetting" and allows the model to leverage its vast pre-trained knowledge to generalize to the new, non-textual traffic domain. This is theoretically more robust against overfitting on small datasets compared to full fine-tuning.

Key Data Structures (Traffic Relation Graph): The TRG is a crucial data structure. By abstracting traffic into nodes (flows) and edges (temporal/concurrency relationships), it transforms a time-series problem into a structural one. This representation is inherently more robust to minor variations in packet timings or sizes within a single flow, as it emphasizes the higher-level interaction architecture.

Optimization Strategy (Two-Stage Parameter-Frozen Tuning): This strategy provides significant computational advantages. As shown in the efficiency experiments (RQ4), full-parameter tuning is infeasible due to memory constraints (OOM errors) . The freezing strategy reduces tunable parameters by over 50x, making the approach practical on modern hardware and drastically cutting training time .

Robustness Design: The model's robustness to O.O.D. scenarios is not an add-on but the central design goal. It is achieved by learning from the more invariant multi-flow interaction patterns captured in the TRG, rather than the more volatile single-flow features. The LLM's reasoning ability then allows it to infer these patterns even when the surface-level features have shifted.

4.4 Method Integration Analysis
Module-Synergy Mechanism: The three modules work in a tightly-coupled pipeline. Traffic2Graph provides the structured data. Graph Structural Tuning acts as a bridge, translating this structure into a format the LLM can comprehend. Traffic-Task Tuning then leverages this understanding for the final objective. The synergy is critical: without the graph representation, the LLM would lack robust input; without the structural tuning, the LLM wouldn't understand the graph's semantics.

End-to-End Processing Pipeline: From a raw PCAP file, the system automatically extracts flows, builds a graph, aligns representations, and performs classification, forming a complete end-to-end pipeline for traffic analysis.

Key Decision Logic: The core "decision" is made during the BURST Graph Matching task, where the model is forced to correlate structural topology with flow features. This foundational understanding enables it to make more robust classification decisions later, even under distribution shift.

5. Experiment Analysis
5.1 Experimental Setup
Dataset Description: The experiments use multiple datasets to ensure a comprehensive evaluation:

APP53 [41]: Used for both I.I.D. and O.O.D. scenarios. The O.O.D. settings involve classifying across different application versions (EACâ‡’V) and different time periods (EACâ‡’T) .

ISCX-Botnet [27]: Used for a challenging O.O.D. malicious traffic classification task, where the test set contains botnet types not seen during training (MSCâ‡’T) .

NETD: A novel dataset constructed by the authors to test generalization under dynamically adjustable and controllable distribution shifts .

Explanation of Evaluation Metrics: Standard classification metrics are used: Accuracy, Precision (PR), Recall (RC), and F1-Score (F1). The Macro Average is used for multi-class tasks to prevent bias from class imbalance .

Introduction of Baseline Methods: A comprehensive set of 7 state-of-the-art methods are used for comparison, spanning statistical (AppScanner, CUMUL), deep learning (DF, FS-Net, GraphDApp), and pre-training (PERT, ET-BERT) approaches .

Experimental Platform and Parameter Configuration: The model is based on Vicuna-7B-v1.5 and trained on NVIDIA Tesla A800 GPUs (80 GB). Key hyperparameters include a learning rate of 2Ã—10 
âˆ’3
  and a BURST time threshold of 1s .

5.2 Detailed Experimental Analysis
Experiment 1: Overall Performance Comparison (RQ1)

Rationale for Experimental Design: To answer the primary research question: How does ETooL perform against state-of-the-art methods in both standard I.I.D. (supervised) and more realistic O.O.D. (zero-shot) traffic classification settings?

Experimental Results: ETooL consistently and significantly outperforms all baseline methods across all tasks.

I.I.D. Scenarios: On APP53, ETooL achieves F1 scores of 93.19% and 92.11%, representing improvements of 6.62% and 4.19% over the best baseline (ET-BERT) . This shows its superior feature learning even in ideal conditions.

O.O.D. Scenarios: The superiority is even more pronounced here. On the APP53 time-shift task, the F1-score of a strong baseline like ET-BERT drops from 86.57% to 56.71%. In contrast, ETooL's score only drops from 93.19% to 74.88%, demonstrating far greater robustness . On the challenging ISCX-Botnet task, ETooL achieves a 95.03% F1 score, a 9.16% improvement over the best baseline .

Corresponding Figure/Table: Table IV details the performance on all APP53 tasks. Table V details the performance on the ISCX-Botnet tasks.

Experiment 2: Ablation Study (RQ2)

Rationale for Experimental Design: To dissect the ETooL framework and quantify the contribution of its individual components (input features, graph structure, LLM) to the overall performance.

Experimental Results: Every component is shown to be crucial.

Removing raw datagrams or packet lengths leads to performance drops of 4.02% and 2.44% in F1-score, respectively, showing both contribute but datagrams are more impactful .

Removing the Graph Structural Tuning phase causes the most catastrophic performance drop, with an average F1 reduction of 22.13%. This proves that teaching the LLM to understand the traffic graph is the most critical part of the methodology .

Replacing the LLM with a standard Graph Transformer (w/o Large Language Model) results in a 12.84% average F1 drop, highlighting that the LLM's inherent reasoning and generalization capabilities are vital for mitigating misclassification under distribution shifts .

Corresponding Figure/Table: Table VI presents the detailed results of the ablation study across five different tasks.

Experiment 3: Generalization Ability on Dynamic Datasets (RQ3)

Rationale for Experimental Design: To evaluate the model's robustness in a more controlled and challenging setting using the newly proposed NETD dataset, which allows for varying degrees and types of distribution shifts.

Experimental Results: ETooL demonstrates superior generalization across all four variants of the NETD dataset. While methods like ET-BERT perform comparably in the I.I.D. setting (the folded line), their performance drops significantly under the Non-I.I.D. conditions. ETooL consistently maintains the highest F1-score, proving its ability to handle both proportional and compositional data biases effectively .

Corresponding Figure/Table: Figure 4 visually compares the performance of all methods on the four NETD datasets, clearly showing ETooL's superior and more stable performance in O.O.D. scenarios.

Experiment 4: Model Efficiency Study (RQ4)

Rationale for Experimental Design: To assess the practicality of the proposed instruction tuning framework in terms of training time, memory usage, and computational load.

Experimental Results: The parameter-freezing strategy is essential for efficiency. Attempting to tune all LLM parameters results in Out of Memory (OOM) errors. The proposed freeze-tuning approach reduces the number of trainable parameters by a factor of more than 50, enabling training on available hardware and significantly cutting down training time (e.g., from OOM to 1h 38min for the traffic task) . While inference latency is too high for real-time line-rate detection, it is practical for offline analysis or human-in-the-loop assisted decision-making .

Corresponding Figure/Table: Table VII provides a clear quantitative comparison of the "tuning" vs. "freeze" strategies across training time, tunable parameters, GPU memory, and FLOPS.

Experiment 5: Hyper-parameter Analysis (RQ5)

Rationale for Experimental Design: To investigate the sensitivity of the model's performance to key hyper-parameter choices, namely the BURST time threshold and the learning rate.

Experimental Results: The model's performance is sensitive to these parameters, but stable within a reasonable range. A BURST time threshold of approximately 1 second yields the best results, balancing the need to group related flows without incorrectly merging unrelated ones . The optimal learning rate was found to be 2Ã—10 
âˆ’3
 , avoiding the instability of a high rate and the slow convergence of a low rate .

Corresponding Figure/Table: Figure 5 plots the F1-score against different values for the BURST Time Threshold (a) and Learning Rate (b), visually demonstrating the optimal ranges.

</details>

## ğŸ¤ Contributing

Contributions are greatly appreciated. Please feel free to fork the repo, create a pull request, or open an issue.

## ğŸŒŸ Future Vision & The DeepRead Bot

The `DeepRead-Agent-Prompt` is a powerful foundation. The future vision is to evolve this into a more robust and accessible tool.

**For a more convenient, one-click experience, we are developing the DeepRead Bot.** This bot will offer features like direct PDF/URL upload, interactive analysis, and knowledge base integration.

Stay tuned for updates! Your support for this open-source project helps accelerate the development of these advanced features.

## ğŸ“œ License

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ“§ Contact

Project Link: [https://github.com/li4oya/DeepRead-Agent-Prompt](https://github.com/li4oya/DeepRead-Agent-Prompt)

</details>

---

<details>
<summary><strong>:cn: ç®€ä½“ä¸­æ–‡æ–‡æ¡£</strong></summary>

## ğŸš€ å…³äºé¡¹ç›®

åœ¨ä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£ï¼Œç ”ç©¶äººå‘˜å’Œå­¦ç”Ÿæ­£è¢«æµ·é‡çš„è®ºæ–‡æ‰€æ·¹æ²¡ã€‚ä¼ ç»Ÿçš„â€œæ€»ç»“ä¸€ä¸‹â€è¿™ç±»æç¤ºè¯æœ€å¤šåªèƒ½æä¾›è‚¤æµ…çš„æ¦‚è§ˆï¼Œå¾€å¾€ä¼šå¿½ç•¥æ–¹æ³•è®ºçš„ç»†å¾®å·®åˆ«ã€ç ”ç©¶çš„èƒŒæ™¯ä»¥åŠå®éªŒç»“æœçš„çœŸæ­£æ„ä¹‰ã€‚

**DeepRead-Agent-Prompt** é€šè¿‡æ¨¡æ‹Ÿä¸€ä¸ªç”±AIä¸“å®¶ç»„æˆçš„åä½œå›¢é˜Ÿæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æ¯ä¸ªâ€œæ™ºèƒ½ä½“â€éƒ½æœ‰æ˜ç¡®çš„åˆ†å·¥â€”â€”ä»è¯†åˆ«æ ¸å¿ƒæ¦‚å¿µåˆ°ä¸€ä¸ä¸è‹Ÿåœ°å‰–ææ–¹æ³•è®ºå’Œå®éªŒè®¾è®¡ã€‚æœ€ç»ˆäº§å‡ºçš„æ˜¯ä¸€ä»½å…¨é¢ã€å¤šç»´åº¦çš„åˆ†ææŠ¥å‘Šï¼Œå…¶æ·±åº¦è¶³ä»¥åª²ç¾äººç±»ä¸“å®¶å›¢é˜Ÿçš„æ°´å¹³ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

*   **ğŸ§  å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿ**ï¼šè°ƒåº¦äº”ä¸ªä¸“ä¸šçš„AIæ™ºèƒ½ä½“ï¼Œè¿›è¡Œå…¨é¢çš„ååŒåˆ†æã€‚
*   **ğŸ”¬ æ·±åº¦æ–¹æ³•å‰–æ**ï¼šè¿œè¶…æ™®é€šæ‘˜è¦ï¼Œå¯¹è®ºæ–‡çš„æŠ€æœ¯æ–¹æ¡ˆè¿›è¡Œé€æ­¥éª¤çš„è§£æ„ã€‚
*   **ğŸ“Š ç»“æ„åŒ–å®éªŒåˆ†æ**ï¼šä»¥æ¸…æ™°çš„â€œç†ç”±-ç»“æœ-å›¾è¡¨â€æ ¼å¼å‘ˆç°å®éªŒç»“æœï¼Œæ˜“äºç†è§£ã€‚
*   **ğŸ§© ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šåˆ†æè®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯ã€æ ¸å¿ƒç§‘å­¦é—®é¢˜åŠå…¶åœ¨æ›´å¹¿é˜”ç ”ç©¶é¢†åŸŸä¸­çš„ä½ç½®ã€‚
*   **ğŸ¤– æ¨¡å‹æ— å…³**ï¼šæ—¨åœ¨ä¸ä»»ä½•å¼ºå¤§çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPT-4o, Claude 4, Gemini 2.5ï¼‰ååŒå·¥ä½œã€‚
*   **ğŸ“– å¼€æ”¾é€æ˜**ï¼šæ•´ä¸ªæç¤ºè¯å®Œå…¨å¼€æºï¼Œå…è®¸ç¤¾åŒºéªŒè¯ã€å®šåˆ¶å’Œæ”¹è¿›ã€‚

## ğŸ¤– æ ¸å¿ƒæç¤ºè¯

è¿™æ˜¯é©±åŠ¨æ•´ä¸ªåˆ†æè¿‡ç¨‹çš„å¼•æ“ã€‚å®ƒè¢«è®¾è®¡æˆä¸€ä¸ªå•ä¸€ã€å¼ºå¤§çš„æç¤ºè¯ï¼Œæ‚¨å¯ä»¥ç›´æ¥æä¾›ç»™æ‚¨é€‰ç”¨çš„å¤§è¯­è¨€æ¨¡å‹ã€‚

<details>
<summary><strong>ç‚¹å‡»æŸ¥çœ‹å®Œæ•´çš„å¤šæ™ºèƒ½ä½“æç¤ºè¯</strong></summary>

```
# ä»»åŠ¡ï¼šå­¦æœ¯è®ºæ–‡æ·±åº¦ååŒåˆ†æ
## è§’è‰²å®šä¹‰

ä½ å°†æ‰®æ¼”ä¸€ä¸ª**é¡¹ç›®åè°ƒå‘˜**çš„è§’è‰²ï¼Œè´Ÿè´£è°ƒåº¦äº”ä¸ªå…·æœ‰ä¸åŒä¸“ä¸šèƒ½åŠ›çš„AIæ™ºèƒ½ä½“æ¥ååŒå®Œæˆä¸€é¡¹ç»¼åˆæ€§çš„è®ºæ–‡æ·±åº¦åˆ†æä»»åŠ¡ã€‚è¿™äº”ä¸ªæ™ºèƒ½ä½“åˆ†åˆ«æ˜¯ï¼š

### 1. å­¦æœ¯å…³é”®è¯æå–ä¸“å®¶

- **èŒè´£**ï¼šä»è®ºæ–‡å†…å®¹ä¸­è¯†åˆ«å¹¶æå–3-5ä¸ªæœ€æ ¸å¿ƒçš„å­¦æœ¯é¢†åŸŸå…³é”®è¯
- **å·¥ä½œé‡ç‚¹**ï¼šç»“åˆæ‘˜è¦ã€æ­£æ–‡å’Œå›¾è¡¨å†…å®¹ï¼Œç¡®ä¿å…³é”®è¯çš„å‡†ç¡®æ€§å’Œä»£è¡¨æ€§

### 2. ç ”ç©¶èƒŒæ™¯åˆ†æä¸“å®¶

- **èŒè´£**ï¼šå…¨é¢åˆ†æè®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯å’Œç›¸å…³å·¥ä½œ
- **å·¥ä½œé‡ç‚¹**ï¼š
    - æ€»ç»“è®ºæ–‡æ‰€å¤„é¢†åŸŸçš„ç ”ç©¶ç°çŠ¶ã€é¢ä¸´çš„æŒ‘æˆ˜å’Œå‘å±•è¶‹åŠ¿
    - **åˆ—å‡ºå¹¶åˆ†æç›¸å…³ç ”ç©¶å·¥ä½œ**ï¼ŒåŒ…æ‹¬é‡è¦çš„å…ˆé©±æ€§ç ”ç©¶å’Œæœ€æ–°è¿›å±•
    - é˜è¿°æœ¬ç ”ç©¶çš„é‡è¦æ€§ã€å¿…è¦æ€§å’Œåˆ›æ–°æ€§è´¡çŒ®
    - å‚è€ƒå¼•è¨€éƒ¨åˆ†å’Œç›¸å…³æ•°æ®å›¾è¡¨

### 3. é—®é¢˜è¯†åˆ«ä¸“å®¶

- **èŒè´£**ï¼šç²¾ç¡®è¯†åˆ«å’Œé˜è¿°è®ºæ–‡çš„æ ¸å¿ƒç§‘å­¦é—®é¢˜
- **å·¥ä½œé‡ç‚¹**ï¼š
    - æ¸…æ™°å®šä¹‰è®ºæ–‡æ—¨åœ¨è§£å†³çš„æ ¸å¿ƒé—®é¢˜
    - åˆ†æè¯¥é—®é¢˜çš„é‡è¦æ€§å’Œç ”ç©¶ä»·å€¼
    - è¯†åˆ«ç°æœ‰æ–¹æ³•çš„å±€é™æ€§å’Œä¸è¶³
    - ç»“åˆé—®é¢˜ç¤ºä¾‹å›¾æˆ–å¯¹æ¯”å›¾å¢å¼ºç†è§£

### 4. æ–¹æ³•è®¾è®¡åˆ†æä¸“å®¶

- **èŒè´£**ï¼šæ·±åº¦è§£æè®ºæ–‡æå‡ºçš„æ–¹æ³•è®ºï¼Œæä¾›**é€æ­¥éª¤ã€å¤šå±‚æ¬¡**çš„æŠ€æœ¯æ–¹æ¡ˆå‰–æ
- **è¯¦ç»†å·¥ä½œè¦æ±‚**ï¼š

#### 4.1 æ–¹æ³•æ€»ä½“æ¶æ„åˆ†æ

- **æ•´ä½“è®¾è®¡ç†å¿µ**ï¼šé˜è¿°æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³å’Œè®¾è®¡å“²å­¦
- **æ¶æ„ç»„ä»¶å›¾è§£**ï¼šç»“åˆç³»ç»Ÿæ¶æ„å›¾ï¼Œè¯¦ç»†è¯´æ˜æ¯ä¸ªæ¨¡å—çš„åŠŸèƒ½å®šä½
- **æ•°æ®æµå‘åˆ†æ**ï¼šè¿½è¸ªæ•°æ®åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä¼ é€’è·¯å¾„å’Œå˜æ¢è¿‡ç¨‹
- **ä¸ç°æœ‰æ–¹æ³•çš„å·®å¼‚**ï¼šçªå‡ºæœ¬æ–¹æ³•çš„åˆ›æ–°æ¶æ„ç‰¹ç‚¹

#### 4.2 å…³é”®æ­¥éª¤é€ä¸€è§£æ

**å¯¹æ–¹æ³•çš„æ¯ä¸ªå…³é”®æ­¥éª¤è¿›è¡Œæ·±åº¦å‰–æ**ï¼š

**æ­¥éª¤Xï¼š[æ­¥éª¤åç§°]**

- **ç›®æ ‡ä¸ä½œç”¨**ï¼šè¯¥æ­¥éª¤è¦è§£å†³ä»€ä¹ˆå…·ä½“é—®é¢˜ï¼Œåœ¨æ•´ä½“æ–¹æ³•ä¸­çš„ä½œç”¨
- **è¾“å…¥è¾“å‡ºå®šä¹‰**ï¼šæ˜ç¡®è¯¥æ­¥éª¤çš„è¾“å…¥æ•°æ®æ ¼å¼å’Œè¾“å‡ºç»“æœ
- **æ ¸å¿ƒç®—æ³•æœºåˆ¶**ï¼š
    - è¯¦ç»†æè¿°ç®—æ³•çš„å·¥ä½œåŸç†
    - è§£é‡Šå…³é”®æ•°å­¦å…¬å¼çš„å«ä¹‰å’Œè®¡ç®—é€»è¾‘
    - åˆ†æç®—æ³•çš„æ—¶é—´/ç©ºé—´å¤æ‚åº¦ï¼ˆå¦‚æœæåŠï¼‰
- **æŠ€æœ¯å®ç°ç»†èŠ‚**ï¼š
    - å…·ä½“çš„è®¡ç®—æµç¨‹å’Œå¤„ç†æ­¥éª¤
    - å…³é”®å‚æ•°çš„è®¾ç½®ä¾æ®å’Œå½±å“
    - ç‰¹æ®Šçš„æ•°æ®å¤„ç†æŠ€å·§æˆ–ä¼˜åŒ–ç­–ç•¥
- **åˆ›æ–°ç‚¹è¯†åˆ«**ï¼šè¯¥æ­¥éª¤ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•çš„æ”¹è¿›ä¹‹å¤„
- **å¯¹åº”å›¾è¡¨å¼•ç”¨**ï¼šæ˜ç¡®æŒ‡å‡ºç›¸å…³çš„ç®—æ³•æµç¨‹å›¾ã€å…¬å¼å›¾ç‰‡æˆ–ç¤ºä¾‹å›¾

#### 4.3 å…³é”®æŠ€æœ¯æ·±åº¦è§£è¯»

- **æ ¸å¿ƒç®—æ³•è¯¦è§£**ï¼š
    - ç®—æ³•çš„æ•°å­¦åŸºç¡€å’Œç†è®ºä¾æ®
    - ç®—æ³•æ”¶æ•›æ€§ã€ç¨³å®šæ€§ç­‰ç†è®ºæ€§è´¨åˆ†æ
    - ç®—æ³•çš„é€‚ç”¨èŒƒå›´å’Œå±€é™æ€§
- **å…³é”®æ•°æ®ç»“æ„**ï¼šé‡è¦çš„æ•°æ®è¡¨ç¤ºæ–¹æ³•å’Œå­˜å‚¨ç­–ç•¥
- **ä¼˜åŒ–ç­–ç•¥åˆ†æ**ï¼šæ€§èƒ½æå‡ã€è®¡ç®—åŠ é€Ÿç­‰ä¼˜åŒ–æ‰‹æ®µ
- **é²æ£’æ€§è®¾è®¡**ï¼šå¤„ç†è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æ•°æ®çš„æœºåˆ¶

#### 4.4 æ–¹æ³•é›†æˆä¸ååŒ

- **æ¨¡å—é—´äº¤äº’**ï¼šä¸åŒç»„ä»¶ä¹‹é—´çš„åä½œæœºåˆ¶
- **ç«¯åˆ°ç«¯æµç¨‹**ï¼šä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆè¾“å‡ºçš„å®Œæ•´å¤„ç†é“¾è·¯
- **å…³é”®å†³ç­–ç‚¹**ï¼šæ–¹æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­çš„é‡è¦åˆ†æ”¯å’Œåˆ¤æ–­é€»è¾‘

### 5. å®éªŒåˆ†æä¸“å®¶

- **èŒè´£**ï¼šç³»ç»Ÿæ€§è¯„ä¼°è®ºæ–‡çš„å®éªŒè®¾è®¡å’Œç»“æœåˆ†æ
- **å·¥ä½œé‡ç‚¹**ï¼š
    - è¯¦ç»†æè¿°**å®éªŒç¯å¢ƒè®¾ç½®**ï¼ˆæ•°æ®é›†ã€è¯„ä¼°æŒ‡æ ‡ã€åŸºçº¿æ–¹æ³•ã€ç¡¬ä»¶é…ç½®ç­‰ï¼‰
    - **æŒ‰ç…§è§„èŒƒåŒ–æ ¼å¼åˆ†ææ¯ä¸ªå®éªŒ**ï¼Œå…·ä½“åŒ…æ‹¬ï¼š
        - **å®éªŒè®¾è®¡çš„ç†ç”±**ï¼šè§£é‡Šä¸ºä»€ä¹ˆè¦è®¾è®¡è¿™ä¸ªå®éªŒï¼Œè¦éªŒè¯ä»€ä¹ˆå‡è®¾
        - **å®éªŒç»“æœ**ï¼šè¯¦ç»†æè¿°å®éªŒçš„å®šé‡å’Œå®šæ€§ç»“æœ
        - **å¯¹åº”å›¾è¡¨**ï¼šæ˜ç¡®æŒ‡å‡ºæ”¯æ’‘è¯¥å®éªŒç»“æœçš„å…·ä½“å›¾è¡¨ç¼–å·å’Œå†…å®¹
    - è¯„ä¼°å®éªŒçš„å……åˆ†æ€§ã€ç§‘å­¦æ€§å’Œè¯´æœåŠ›

## è¾“å…¥ææ–™

ä½ å°†æ¥æ”¶ä»¥ä¸‹å®Œæ•´çš„è®ºæ–‡ææ–™ï¼š

- **è®ºæ–‡æ‘˜è¦**ï¼šæ ¸å¿ƒå†…å®¹æ¦‚è¿°
- **è®ºæ–‡æ­£æ–‡**ï¼šç»è¿‡æ·±åº¦æ¸…æ´—å’Œé¢„å¤„ç†çš„å…¨æ–‡æ–‡æœ¬
- **å›¾ç‰‡èµ„æºåˆ—è¡¨**ï¼šåŒ…å«è®ºæ–‡æ¯ä¸€é¡µçš„é«˜æ¸…å›¾ç‰‡è·¯å¾„ï¼Œæ¶µç›–å›¾è¡¨ã€å…¬å¼ã€ç®—æ³•æµç¨‹å›¾å’Œç³»ç»Ÿæ¶æ„å›¾

## æ‰§è¡Œæµç¨‹

### é˜¶æ®µä¸€ï¼šä»»åŠ¡åˆ†å‘ä¸æŒ‡å¯¼

1. å°†è®ºæ–‡ææ–™ï¼ˆæ‘˜è¦ã€æ­£æ–‡ã€å›¾ç‰‡èµ„æºï¼‰åˆ†å‘ç»™æ‰€æœ‰äº”ä¸ªä¸“ä¸šæ™ºèƒ½ä½“
2. ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“æä¾›é’ˆå¯¹æ€§çš„å·¥ä½œæŒ‡å¯¼ï¼š
    - æŒ‡å¯¼**å…³é”®è¯æå–ä¸“å®¶**ç»“åˆå¤šç»´åº¦ä¿¡æ¯æç‚¼ç²¾å‡†å…³é”®è¯
    - æŒ‡å¯¼**ç ”ç©¶èƒŒæ™¯åˆ†æä¸“å®¶**æ·±å…¥æŒ–æ˜ç›¸å…³å·¥ä½œå’Œç ”ç©¶ç°çŠ¶
    - æŒ‡å¯¼**é—®é¢˜è¯†åˆ«ä¸“å®¶**å‡†ç¡®å®šä½æ ¸å¿ƒé—®é¢˜åŠå…¶é‡è¦æ€§
    - é‡ç‚¹æŒ‡å¯¼**æ–¹æ³•è®¾è®¡åˆ†æä¸“å®¶**åˆ©ç”¨å›¾ç‰‡èµ„æºç†è§£å¤æ‚æŠ€æœ¯ç»†èŠ‚ï¼ŒæŒ‰ç…§4.1-4.4çš„è¯¦ç»†è¦æ±‚è¿›è¡Œé€æ­¥éª¤æ·±åº¦è§£æ
    - é‡ç‚¹æŒ‡å¯¼**å®éªŒåˆ†æä¸“å®¶**æŒ‰ç…§æ ‡å‡†åŒ–æ ¼å¼è§£ææ¯ä¸ªå®éªŒçš„å®Œæ•´é€»è¾‘

### é˜¶æ®µäºŒï¼šåè°ƒä¸æ•´åˆ

æ”¶é›†å¹¶æ•´åˆæ‰€æœ‰æ™ºèƒ½ä½“çš„ä¸“ä¸šåˆ†æç»“æœï¼Œå½¢æˆç»“æ„åŒ–çš„ç»¼åˆæŠ¥å‘Š

## æœ€ç»ˆäº¤ä»˜ç‰©

ç”Ÿæˆä¸€ä»½**ç»“æ„æ¸…æ™°ã€å†…å®¹è¯¦å®**çš„ç»¼åˆåˆ†ææŠ¥å‘Šï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹äº”ä¸ªéƒ¨åˆ†ç»„ç»‡ï¼š

### 1. æ ¸å¿ƒå…³é”®è¯

- 3-5ä¸ªæœ€å…·ä»£è¡¨æ€§çš„å­¦æœ¯å…³é”®è¯
- æ¯ä¸ªå…³é”®è¯çš„ç®€è¦è¯´æ˜

### 2. ç ”ç©¶èƒŒæ™¯ä¸ç›¸å…³å·¥ä½œ

- ç ”ç©¶é¢†åŸŸç°çŠ¶å’Œå‘å±•è¶‹åŠ¿
- **ç›¸å…³ç ”ç©¶å·¥ä½œåˆ—è¡¨åŠå…¶è´¡çŒ®åˆ†æ**
- æœ¬ç ”ç©¶çš„åˆ›æ–°æ€§å’Œé‡è¦æ€§

### 3. æ ¸å¿ƒç§‘å­¦é—®é¢˜

- å¾…è§£å†³é—®é¢˜çš„æ¸…æ™°å®šä¹‰
- é—®é¢˜çš„é‡è¦æ€§å’ŒæŒ‘æˆ˜æ€§
- ç°æœ‰æ–¹æ³•çš„å±€é™æ€§

### 4. æ–¹æ³•è®¾è®¡è¯¦è§£

#### 4.1 æ–¹æ³•æ€»ä½“æ¶æ„

- æ•´ä½“è®¾è®¡ç†å¿µï¼š...
- æ¶æ„ç»„ä»¶åˆ†æï¼šï¼ˆå‚è€ƒå›¾Xï¼‰...
- æ•°æ®æµå‘ï¼š...
- åˆ›æ–°æ¶æ„ç‰¹ç‚¹ï¼š...

#### 4.2 å…³é”®æ­¥éª¤è¯¦ç»†è§£æ

**æ­¥éª¤1ï¼š[å…·ä½“æ­¥éª¤åç§°]**
â€¢ ç›®æ ‡ä¸ä½œç”¨ï¼š...
â€¢ è¾“å…¥è¾“å‡ºï¼š...
â€¢ æ ¸å¿ƒç®—æ³•æœºåˆ¶ï¼š

- å·¥ä½œåŸç†ï¼š...
- æ•°å­¦å…¬å¼è§£è¯»ï¼š...
- å¤æ‚åº¦åˆ†æï¼š...  

    â€¢ æŠ€æœ¯å®ç°ç»†èŠ‚ï¼š
- å…·ä½“è®¡ç®—æµç¨‹ï¼š...
- å‚æ•°è®¾ç½®ï¼š...
- ä¼˜åŒ–ç­–ç•¥ï¼š...  

    â€¢ åˆ›æ–°ç‚¹ï¼š...  

    â€¢ å¯¹åº”å›¾è¡¨ï¼šå›¾Xæ˜¾ç¤ºäº†...

**[å¯¹æ¯ä¸ªå…³é”®æ­¥éª¤é‡å¤ä¸Šè¿°æ ¼å¼]**

#### 4.3 æ ¸å¿ƒæŠ€æœ¯æ·±åº¦åˆ†æ

##### 4.3.1 å­¦ç§‘å½’å±ä¸ç†è®ºåŸºç¡€

- **ä¸»è¦å­¦ç§‘é¢†åŸŸ**ï¼šæ˜ç¡®è¯†åˆ«è®ºæ–‡æ–¹æ³•æ‰€å±çš„æ ¸å¿ƒå­¦ç§‘ï¼ˆå¦‚æœºå™¨å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€ä¿¡å·å¤„ç†ã€ç»Ÿè®¡å­¦ã€æ•°å­¦ä¼˜åŒ–ã€æ§åˆ¶è®ºç­‰ï¼‰
- **äº¤å‰å­¦ç§‘è¯†åˆ«**ï¼šè¯†åˆ«æ¶‰åŠçš„è·¨å­¦ç§‘ç†è®ºï¼ˆå¦‚è®¤çŸ¥ç§‘å­¦ã€ç¥ç»ç§‘å­¦ã€ä¿¡æ¯è®ºã€å›¾è®ºã€åšå¼ˆè®ºç­‰ï¼‰
- **ç†è®ºåŸºç¡€è„‰ç»œ**ï¼š
    - æ•°å­¦åŸºç¡€ï¼šç›¸å…³çš„æ¦‚ç‡è®ºã€çº¿æ€§ä»£æ•°ã€å¾®ç§¯åˆ†ã€ç»Ÿè®¡å­¦ã€æ‹“æ‰‘å­¦ç­‰æ•°å­¦ç†è®º
    - ç®—æ³•ç†è®ºï¼šæ‰€é‡‡ç”¨ç®—æ³•çš„ç†è®ºæ¥æºï¼ˆå¦‚æ·±åº¦å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€è¿›åŒ–ç®—æ³•ã€å›¾ç®—æ³•ã€ä¼˜åŒ–ç†è®ºç­‰ï¼‰
    - é¢†åŸŸç‰¹å®šç†è®ºï¼šä¸“ä¸šé¢†åŸŸçš„æ ¸å¿ƒç†è®ºæ¡†æ¶å’ŒåŸºç¡€å‡è®¾
- **æ–¹æ³•å­¦è°±ç³»**ï¼šè¯¥æ–¹æ³•åœ¨ç›¸åº”å­¦ç§‘å‘å±•å²ä¸­çš„ä½ç½®ã€æ¼”è¿›å…³ç³»å’Œç†è®ºä¼ æ‰¿

##### 4.3.2 æ ¸å¿ƒç®—æ³•è¯¦è§£

- ç®—æ³•çš„æ•°å­¦åŸºç¡€å’Œç†è®ºä¾æ®
- ç®—æ³•æ”¶æ•›æ€§ã€ç¨³å®šæ€§ç­‰ç†è®ºæ€§è´¨åˆ†æ
- ç®—æ³•çš„é€‚ç”¨èŒƒå›´å’Œå±€é™æ€§

##### 4.3.3 å…³é”®æ•°æ®ç»“æ„ä¸è¡¨ç¤º

- é‡è¦çš„æ•°æ®è¡¨ç¤ºæ–¹æ³•å’Œå­˜å‚¨ç­–ç•¥
- æ•°æ®ç»“æ„é€‰æ‹©çš„ç†è®ºä¼˜åŠ¿å’Œè®¡ç®—æ•ˆç‡

##### 4.3.4 ä¼˜åŒ–ç­–ç•¥åˆ†æ

- æ€§èƒ½æå‡ã€è®¡ç®—åŠ é€Ÿç­‰ä¼˜åŒ–æ‰‹æ®µ
- ä¼˜åŒ–ç­–ç•¥çš„ç†è®ºåŸºç¡€å’Œé€‚ç”¨æ¡ä»¶

##### 4.3.5 é²æ£’æ€§è®¾è®¡

- å¤„ç†è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸æ•°æ®çš„æœºåˆ¶
- ç¨³å®šæ€§ä¿è¯çš„ç†è®ºä¾æ®å’Œå®ç°æ–¹æ³•

#### 4.4 æ–¹æ³•é›†æˆåˆ†æ

- æ¨¡å—ååŒæœºåˆ¶ï¼š...
- ç«¯åˆ°ç«¯å¤„ç†æµç¨‹ï¼š...
- å…³é”®å†³ç­–é€»è¾‘ï¼š...

### 5. å®éªŒåˆ†æ

#### 5.1 å®éªŒç¯å¢ƒè®¾ç½®

- **æ•°æ®é›†æè¿°**
- **è¯„ä¼°æŒ‡æ ‡è¯´æ˜**
- **åŸºçº¿æ–¹æ³•ä»‹ç»**
- **å®éªŒå¹³å°å’Œå‚æ•°é…ç½®**

#### 5.2 å®éªŒè¯¦ç»†åˆ†æ

**é’ˆå¯¹æ¯ä¸ªå®éªŒï¼ŒæŒ‰ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦è¿›è¡Œåˆ†æ**ï¼š

**å®éªŒXï¼š[å®éªŒåç§°]**

- **å®éªŒè®¾è®¡çš„ç†ç”±**ï¼šè¯¥å®éªŒæ—¨åœ¨éªŒè¯ä»€ä¹ˆå‡è®¾æˆ–å›ç­”ä»€ä¹ˆé—®é¢˜
- **å®éªŒç»“æœ**ï¼šè¯¦ç»†çš„å®šé‡æ•°æ®å’Œå®šæ€§åˆ†æç»“æœ
- **å¯¹åº”å›¾è¡¨**ï¼šæ˜ç¡®æ ‡æ³¨æ”¯æ’‘è¯¥ç»“æœçš„å›¾è¡¨ç¼–å·ï¼ˆå¦‚å›¾Xã€è¡¨Yç­‰ï¼‰

## è´¨é‡è¦æ±‚

- **ä¸“ä¸šæ€§**ï¼šç¡®ä¿æ¯éƒ¨åˆ†éƒ½ç”±ç›¸åº”é¢†åŸŸä¸“å®¶å®Œæˆ
- **å®Œæ•´æ€§**ï¼šå……åˆ†åˆ©ç”¨æä¾›çš„æ–‡æœ¬å’Œå›¾ç‰‡ä¿¡æ¯
- **å‡†ç¡®æ€§**ï¼šç‰¹åˆ«æ³¨é‡æ–¹æ³•è®ºå’Œå®éªŒéƒ¨åˆ†çš„æŠ€æœ¯ç»†èŠ‚è§£è¯»
- **æ·±åº¦æ€§**ï¼šæ–¹æ³•è®¾è®¡éƒ¨åˆ†å¿…é¡»æä¾›é€æ­¥éª¤çš„æ·±åº¦æŠ€æœ¯å‰–æ
- **è§„èŒƒæ€§**ï¼šå®éªŒåˆ†æéƒ¨åˆ†ä¸¥æ ¼æŒ‰ç…§"ç†ç”±-ç»“æœ-å›¾è¡¨"çš„ä¸‰æ®µå¼ç»“æ„
- **æ¡ç†æ€§**ï¼šæŠ¥å‘Šç»“æ„æ¸…æ™°ï¼Œé€»è¾‘è¿è´¯
- **å›¾è¡¨å…³è”æ€§**ï¼šç¡®ä¿æ¯ä¸ªæŠ€æœ¯è¦ç‚¹éƒ½æœ‰æ˜ç¡®çš„å›¾è¡¨æ”¯æ’‘å’Œå¼•ç”¨

---

**è¯·æŒ‰ç…§ä¸Šè¿°è¦æ±‚ï¼Œå¼€å§‹æ‰§è¡Œå­¦æœ¯è®ºæ–‡çš„æ·±åº¦ååŒåˆ†æä»»åŠ¡ã€‚**
```

</details>

## ğŸ› ï¸ å¦‚ä½•ä½¿ç”¨

1.  **å¤åˆ¶æç¤ºè¯**: å¤åˆ¶ä¸Šæ–¹åŒºåŸŸå†…çš„å®Œæ•´æ ¸å¿ƒæç¤ºè¯ã€‚
2.  **å‡†å¤‡ææ–™**:
    *   å°†ä½ çš„ç›®æ ‡è®ºæ–‡ï¼ˆä¾‹å¦‚ PDF æ–‡ä»¶ï¼‰è½¬æ¢ä¸ºçº¯æ–‡æœ¬(è‹¥å¯¹è¯ç½‘ç«™å·²ç»æœ‰å¾ˆå¥½çš„å¯¹PDFçš„å¤„ç†ï¼Œå¯ä»¥ç›´æ¥ä¸¢PDF)ã€‚
    *   ï¼ˆå¯é€‰ä½†æ¨èï¼‰å¦‚æœè®ºæ–‡ä¸­æœ‰å…³é”®çš„å›¾è¡¨æˆ–å…¬å¼ï¼Œè¯·è®°ä¸‹å®ƒä»¬çš„ç¼–å·ã€‚
3.  **ä¸å¤§æ¨¡å‹äº¤äº’**:
    *   åœ¨ä½ é€‰ç”¨çš„å¤§æ¨¡å‹ï¼ˆå¦‚ Gemini pro 2.5ï¼‰çš„å¯¹è¯ç•Œé¢ä¸­ã€‚
    *   å°† **DeepRead-Agent-Prompt** ä½œä¸ºä½ çš„ç¬¬ä¸€æ¡æ¶ˆæ¯ç²˜è´´å¹¶å‘é€ã€‚
    *   åœ¨åŒä¸€æ¡æ¶ˆæ¯ä¸­ï¼Œæä¾›è®ºæ–‡çš„æ–‡æœ¬å’Œå›¾è¡¨ä¿¡æ¯ï¼ˆæˆ–è€…ç›´æ¥æä¾›PDFï¼‰ã€‚
4.  **æ¥æ”¶åˆ†ææŠ¥å‘Š**: å¤§æ¨¡å‹å°†éµå¾ªå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†ã€ç»“æ„åŒ–çš„æŠ¥å‘Šã€‚

## ğŸ’¡ è¾“å‡ºç¤ºä¾‹

ä»¥ä¸‹æ˜¯é’ˆå¯¹è®ºæ–‡ *ã€ŠRespond to Change With Constancy: Instruction-Tuning With LLM for Non-I.I.D.Network Traffic Classificationã€‹* ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šç²¾ç®€ç¤ºä¾‹ã€‚

<details>
<summary><strong>ç‚¹å‡»æŸ¥çœ‹åˆ†æç¤ºä¾‹</strong></summary>

### **ç»¼åˆåˆ†ææŠ¥å‘Š**

**è®ºæ–‡é¢˜ç›®ï¼š**Respond to Change With Constancy: Instruction-Tuning With LLM for Non-I.I.D.Network Traffic Classification

---

### **1. æ ¸å¿ƒå…³é”®è¯**

ç”±**å­¦æœ¯å…³é”®è¯æå–ä¸“å®¶**åˆ†ææ‘˜è¦ã€å¼•è¨€å’Œç»“è®ºåï¼Œæç‚¼å‡ºä»¥ä¸‹æ ¸å¿ƒå…³é”®è¯ï¼š

- **Encrypted Traffic Classification (åŠ å¯†æµé‡åˆ†ç±»):**æœ¬ç ”ç©¶çš„æ ¸å¿ƒä»»åŠ¡ï¼Œå³åœ¨æ— æ³•è®¿é—®æµé‡æ˜æ–‡å†…å®¹çš„æƒ…å†µä¸‹ï¼Œè¯†åˆ«å’Œåˆ†ç±»ç½‘ç»œæµé‡çš„æ¥æºï¼ˆå¦‚å…·ä½“åº”ç”¨æˆ–æœåŠ¡ï¼‰ã€‚è¿™æ˜¯ç½‘ç»œå®‰å…¨å’Œç®¡ç†çš„åŸºç¡€æŠ€æœ¯ã€‚
- **Out-of-Distribution (O.O.D.) Generalization (åˆ†å¸ƒå¤–æ³›åŒ–):**è®ºæ–‡æ—¨åœ¨è§£å†³çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚æŒ‡æ¨¡å‹åœ¨é¢å¯¹ä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸ä¸€è‡´ï¼ˆå³Non-I.I.D.ï¼‰çš„æµ‹è¯•æ•°æ®æ—¶ï¼Œä»èƒ½ä¿æŒé«˜æ€§èƒ½çš„èƒ½åŠ›ã€‚ç°å®ç½‘ç»œä¸­ï¼Œåº”ç”¨æ›´æ–°ã€æ—¶é—´å˜åŒ–ç­‰å› ç´ éƒ½ä¼šå¯¼è‡´æ•°æ®åˆ†å¸ƒæ¼‚ç§»ã€‚
- **Large Language Models (LLM, å¤§è¯­è¨€æ¨¡å‹):**æœ¬ç ”ç©¶é‡‡ç”¨çš„æ ¸å¿ƒæŠ€æœ¯ã€‚åˆ©ç”¨LLMå¼ºå¤§çš„çŸ¥è¯†å‚¨å¤‡ã€æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä½œä¸ºè§£å†³O.O.D.é—®é¢˜çš„æ–°èŒƒå¼ã€‚
- **Instruction Tuning (æŒ‡ä»¤å¾®è°ƒ):**å®ç°LLMä¸æµé‡åˆ†æä»»åŠ¡å¯¹é½çš„å…³é”®æ–¹æ³•ã€‚é€šè¿‡è®¾è®¡ç‰¹å®šæ ¼å¼çš„æŒ‡ä»¤æ¥å¼•å¯¼é¢„è®­ç»ƒçš„LLMé€‚åº”æ–°é¢†åŸŸçš„ä»»åŠ¡ï¼Œä»è€Œåœ¨å°‘é‡ç”šè‡³é›¶æ ·æœ¬çš„æƒ…å†µä¸‹å®ç°æœ‰æ•ˆçš„çŸ¥è¯†è¿ç§»å’Œæ³›åŒ–ã€‚

---

### **2. ç ”ç©¶èƒŒæ™¯ä¸ç›¸å…³å·¥ä½œ**

ç”±**ç ”ç©¶èƒŒæ™¯åˆ†æä¸“å®¶**åŸºäºå¼•è¨€å’Œç›¸å…³å·¥ä½œéƒ¨åˆ†ï¼Œè¿›è¡Œæ·±åº¦æ¢³ç†ï¼š

- **ç ”ç©¶é¢†åŸŸç°çŠ¶å’Œå‘å±•è¶‹åŠ¿:**
    - **ç°çŠ¶ï¼š**éšç€ç½‘ç»œæµé‡å…¨é¢åŠ å¯†æˆä¸ºå¸¸æ€ï¼Œä¼ ç»Ÿçš„æ·±åº¦åŒ…æ£€æµ‹ï¼ˆDPIï¼‰æŠ€æœ¯é€æ¸å¤±æ•ˆã€‚ç°æœ‰åŠ å¯†æµé‡åˆ†ææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸‰ç±»ï¼šåŸºäºç»Ÿè®¡ç‰¹å¾çš„æ–¹æ³•ã€åŸºäºåŸå§‹æµé‡ç‰¹å¾çš„æ–¹æ³•å’ŒåŸºäºåŸå§‹æŠ¥æ–‡çš„æ–¹æ³•ã€‚
    - **æŒ‘æˆ˜ï¼š**è¿™äº›æ–¹æ³•å¤§å¤šåŸºäºä¸€ä¸ªè„†å¼±çš„å‡è®¾ï¼šè®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆI.I.D.ï¼‰çš„ã€‚ç„¶è€Œï¼Œåœ¨çœŸå®çš„ç½‘ç»œç¯å¢ƒä¸­ï¼Œåº”ç”¨ç‰ˆæœ¬æ›´æ–°ã€ç”¨æˆ·è¡Œä¸ºå˜åŒ–ç­‰å› ç´ å¯¼è‡´æµé‡çš„æ¦‚ç‡åˆ†å¸ƒæŒç»­æ¼‚ç§»ï¼ˆå³O.O.D.é—®é¢˜ï¼‰ï¼Œä½¿å¾—æ¨¡å‹æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚ä¼ ç»Ÿåº”å¯¹ç­–ç•¥ï¼ˆå¦‚å‘¨æœŸæ€§é‡è®­ç»ƒï¼‰æˆæœ¬é«˜æ˜‚ï¼Œä¸”é¢ä¸´â€œç¾éš¾æ€§é—å¿˜â€é—®é¢˜ã€‚
    - **å‘å±•è¶‹åŠ¿ï¼š**é¢„è®­ç»ƒæŠ€æœ¯ï¼ˆå¦‚ET-BERTï¼‰åœ¨æµé‡åˆ†æé¢†åŸŸå±•ç°äº†è‰¯å¥½çš„æ³›åŒ–æ½œåŠ›ï¼Œä½†æœªèƒ½å®Œå…¨è§£å†³O.O.D.æŒ‘æˆ˜ã€‚ä¸æ­¤åŒæ—¶ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å› å…¶å¼ºå¤§çš„è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›å’Œå¯¹æŒ‡ä»¤çš„ç†è§£èƒ½åŠ›ï¼Œè¢«è§†ä¸ºè§£å†³å¤æ‚é¢†åŸŸé€‚åº”æ€§é—®é¢˜çš„æ–°å…´åŠ›é‡ã€‚å°†LLMé€šè¿‡æŒ‡ä»¤å¾®è°ƒèŒƒå¼åº”ç”¨äºç‰¹å®šé¢†åŸŸæˆä¸ºå‰æ²¿è¶‹åŠ¿ã€‚
- **ç›¸å…³ç ”ç©¶å·¥ä½œåˆ—è¡¨åŠå…¶è´¡çŒ®åˆ†æ:**
    - ç»Ÿè®¡ç‰¹å¾æ–¹æ³• (å¦‚CUMUL, AppScanner): ä¾èµ–ä¸“å®¶æ‰‹åŠ¨è®¾è®¡ç»Ÿè®¡ç‰¹å¾ï¼ˆå¦‚åŒ…å¤§å°ï¼‰ï¼Œè™½ç„¶èƒ½å¤„ç†åŠ å¯†æµé‡ï¼Œä½†éš¾ä»¥é€‚åº”å¿«é€Ÿå˜åŒ–çš„åº”ç”¨å’Œç½‘ç»œç¯å¢ƒã€‚
    - æ·±åº¦å­¦ä¹ æ–¹æ³• (å¦‚FS-Net, Deeppacket, GraphDApp): èƒ½å¤Ÿè‡ªåŠ¨ä»åŸå§‹æµé‡ä¸­æå–ç‰¹å¾ï¼Œä½†ä¸¥é‡ä¾èµ–å¤§è§„æ¨¡æœ‰ç›‘ç£æ•°æ®ï¼Œä¸”åŒæ ·å—é™äºI.I.D.å‡è®¾ã€‚
    - é¢„è®­ç»ƒæ–¹æ³• (å¦‚PERT, ET-BERT): é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ä»æœªæ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ é€šç”¨æµé‡è¡¨ç¤ºï¼Œæå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†æœªä¸“é—¨é’ˆå¯¹O.O.D.é—®é¢˜è¿›è¡Œè®¾è®¡ã€‚
- **æœ¬ç ”ç©¶çš„åˆ›æ–°æ€§å’Œé‡è¦æ€§:**
    - **åˆ›æ–°æ€§ï¼š**é¦–æ¬¡æå‡ºä¸€ä¸ªåä¸ºETooLçš„æµé‡å›¾è°±æŒ‡ä»¤å¾®è°ƒæ¡†æ¶ï¼Œå°†æµé‡çš„ç»“æ„åŒ–çŸ¥è¯†ï¼ˆå¤šæµäº¤äº’å›¾ï¼‰ä¸LLMçš„æ³›åŒ–èƒ½åŠ›ç›¸ç»“åˆï¼Œä»¥åº”å¯¹O.O.D.åŠ å¯†æµé‡åˆ†ç±»é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¿˜æ„å»ºäº†ä¸€ä¸ªæ”¯æŒåŠ¨æ€åˆ†å¸ƒè°ƒæ•´çš„æ–°æ•°æ®é›†NETDï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸç ”ç©¶èµ„æºçš„ç©ºç™½ã€‚
    - **é‡è¦æ€§ï¼š**æœ¬ç ”ç©¶ä¸ºè§£å†³ç°å®ä¸–ç•Œä¸­åŠ¨æ€ã€å˜åŒ–çš„åŠ å¯†æµé‡åˆ†æéš¾é¢˜æä¾›äº†ä¸€ç§å…¨æ–°çš„ã€æ›´å…·é²æ£’æ€§çš„è§£å†³æ–¹æ¡ˆã€‚å®ƒæ‘†è„±äº†å¯¹æŒç»­é‡è®­ç»ƒçš„ä¾èµ–ï¼Œé€šè¿‡â€œä»¥ä¸å˜åº”ä¸‡å˜â€çš„æ€è·¯ï¼Œè®©æ¨¡å‹å­¦ä¹ æµé‡ä¸­æ›´æœ¬è´¨ã€æ›´ç¨³å®šçš„äº¤äº’æ¨¡å¼ï¼Œå¯¹æå‡ç½‘ç»œå®‰å…¨é˜²å¾¡ç³»ç»Ÿçš„è‡ªé€‚åº”èƒ½åŠ›å…·æœ‰é‡è¦æ„ä¹‰ã€‚

---

### **3. æ ¸å¿ƒç§‘å­¦é—®é¢˜**

ç”±**é—®é¢˜è¯†åˆ«ä¸“å®¶**ç²¾ç¡®æç‚¼è®ºæ–‡è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š

- **å¾…è§£å†³é—®é¢˜çš„æ¸…æ™°å®šä¹‰:**å¦‚ä½•æ„å»ºä¸€ä¸ªåŠ å¯†æµé‡åˆ†ç±»æ¨¡å‹ï¼Œä½¿å…¶åœ¨é¢å¯¹ç”±åº”ç”¨æ›´æ–°ã€æ—¶é—´æ¨ç§»ç­‰å› ç´ å¼•èµ·çš„ç½‘ç»œæµé‡åˆ†å¸ƒæ¼‚ç§»ï¼ˆOut-of-Distributionï¼‰æ—¶ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€é‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œä¾ç„¶ä¿æŒé«˜å‡†ç¡®ç‡å’Œå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Ÿ
- **é—®é¢˜çš„é‡è¦æ€§å’ŒæŒ‘æˆ˜æ€§:**
    - **é‡è¦æ€§:**ç°å®ä¸–ç•Œçš„ç½‘ç»œæµé‡æœ¬è´¨ä¸Šæ˜¯åŠ¨æ€å’Œéå¹³ç¨³çš„ï¼ˆNon-I.I.D.ï¼‰ã€‚ä¾èµ–I.I.D.å‡è®¾çš„æ¨¡å‹åœ¨å®é™…éƒ¨ç½²ä¸­æ€§èƒ½ä¼šä¸¥é‡ä¸‹é™ï¼Œè¿™å¯¹äºç½‘ç»œæ”»å‡»æ£€æµ‹ã€æœåŠ¡è´¨é‡ä¿éšœç­‰å…³é”®å®‰å…¨ä»»åŠ¡æ˜¯è‡´å‘½çš„ã€‚
    - **æŒ‘æˆ˜æ€§:** ä¸»è¦æŒ‘æˆ˜åœ¨äºä¸¤ç‚¹ï¼š(1) **ç‰¹å¾ä¸ç¨³å®šæ€§(Feature Instability):**å•ä¸€æ•°æ®æµçš„ç‰¹å¾åœ¨åˆ†å¸ƒå˜åŒ–æ—¶éå¸¸è„†å¼±ã€‚(2) **æ³›åŒ–èƒ½åŠ›ä¸è¶³(Insufficient Generalization):**ç°æœ‰æ¨¡å‹æ—¨åœ¨æ‹Ÿåˆç‰¹å®šçš„è®­ç»ƒåˆ†å¸ƒï¼Œç¼ºä¹å‘æœªçŸ¥åˆ†å¸ƒè¿ç§»çš„èƒ½åŠ›ã€‚
- **ç°æœ‰æ–¹æ³•çš„å±€é™æ€§:**
    - ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–ä¸ç¨³å®šçš„å•æµç‰¹å¾ï¼Œå¹¶ä¸”ä¸ºç‰¹å®šåˆ†å¸ƒè®¾è®¡ï¼Œæ³›åŒ–èƒ½åŠ›å·®ã€‚
    - æœ€ç›´æ¥çš„è§£å†³æ–¹æ¡ˆâ€”â€”å‘¨æœŸæ€§åœ°ç”¨æ–°æ ‡æ³¨æ•°æ®é‡è®­ç»ƒæ¨¡å‹ï¼Œä¸ä»…æ¶ˆè€—å¤§é‡æ—¶é—´å’ŒäººåŠ›ï¼Œè¿˜ä¼šåœ¨é€‚åº”æ–°åˆ†å¸ƒçš„åŒæ—¶å¿˜è®°æ—§åˆ†å¸ƒçš„çŸ¥è¯†ã€‚
    - å›¾1(a) ç›´è§‚åœ°å±•ç¤ºäº†ä¼ ç»Ÿæ–¹æ³•åœ¨é¢å¯¹åˆ†å¸ƒæ¼‚ç§»æ—¶çš„â€œé—å¿˜â€å›°å¢ƒã€‚

---

### **4. æ–¹æ³•è®¾è®¡è¯¦è§£**

ç”±**æ–¹æ³•è®¾è®¡åˆ†æä¸“å®¶**è¿›è¡Œæ·±åº¦ã€é€æ­¥éª¤çš„æŠ€æœ¯å‰–æï¼š

#### **4.1 æ–¹æ³•æ€»ä½“æ¶æ„**

- **æ•´ä½“è®¾è®¡ç†å¿µï¼š**æ ¸å¿ƒæ€æƒ³æ˜¯å­¦ä¹ æµé‡ä¸­æ¯”å•æµç‰¹å¾æ›´ç¨³å®šã€æ›´é€šç”¨çš„â€œå¤šæµäº¤äº’å…³è”æ¨¡å¼â€ï¼Œå¹¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å“è¶Šçš„æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›ï¼Œé€šè¿‡æŒ‡ä»¤å¾®è°ƒä½¿å…¶ç†è§£è¿™äº›æ¨¡å¼ï¼Œä»è€Œåœ¨åˆ†å¸ƒå˜åŒ–æ—¶ä¹Ÿèƒ½åšå‡ºå‡†ç¡®åˆ†ç±»ï¼Œå®ç°â€œä»¥ä¸å˜ï¼ˆç¨³å®šçš„äº¤äº’æ¨¡å¼ï¼‰åº”ä¸‡å˜ï¼ˆåŠ¨æ€çš„æµé‡åˆ†å¸ƒï¼‰â€ã€‚
- æ¶æ„ç»„ä»¶åˆ†æï¼ˆå‚è€ƒå›¾2ï¼‰: ETooLæ¡†æ¶åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªä¸¤é˜¶æ®µå¾®è°ƒæµç¨‹å®ç°ï¼š

    ![](https://secure2.wostatic.cn/static/MTwNybn5MfR2gNtga9sZP/image.png?auth_key=1760083772-7uh4fzWv2Z62E2aTT7ZCJ6-0-e8125bc54e69859d32b6dcc23658da4b)

    1. **Traffic2Graph:**æµé‡åˆ°å›¾çš„è½¬æ¢æ¨¡å—ã€‚è´Ÿè´£å°†åŸå§‹ç½‘ç»œæµé‡ï¼ˆPCAP Traceï¼‰é¢„å¤„ç†å¹¶æ„å»ºæˆä¸€ä¸ªèƒ½è¡¨ç¤ºå¤šæµäº¤äº’å…³ç³»çš„â€œæµé‡å…³ç³»å›¾â€ï¼ˆTraffic Relation Graph, TRGï¼‰ã€‚
    2. **Graph Structural Instruction Tuning:**å›¾ç»“æ„æŒ‡ä»¤å¾®è°ƒé˜¶æ®µã€‚è¿™æ˜¯ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ é˜¶æ®µï¼Œæ—¨åœ¨è®©LLMç†è§£TRGçš„æ‹“æ‰‘ç»“æ„å’ŒèŠ‚ç‚¹ç‰¹å¾ã€‚å®ƒåŒ…å«â€œæµé‡å›¾ç¼–ç å¯¹é½â€å’Œâ€œBURSTå›¾åŒ¹é…â€ä¸¤ä¸ªå­ä»»åŠ¡ã€‚
    3. **Traffic-Task Instruction Tuning:**æµé‡ä»»åŠ¡æŒ‡ä»¤å¾®è°ƒé˜¶æ®µã€‚åœ¨LLMå…·å¤‡å›¾ç†è§£èƒ½åŠ›åï¼Œæ­¤é˜¶æ®µä½¿ç”¨å°‘é‡æœ‰æ ‡ç­¾æ•°æ®ï¼Œé€šè¿‡ç‰¹å®šä»»åŠ¡æŒ‡ä»¤ï¼Œå°†æ¨¡å‹çš„èƒ½åŠ›èšç„¦åˆ°æœ€ç»ˆçš„æµé‡åˆ†ç±»ä»»åŠ¡ä¸Šã€‚
- **æ•°æ®æµå‘:** æ•´ä¸ªæµç¨‹å¦‚**å›¾2**æ‰€ç¤ºï¼šåŸå§‹PCAPåŒ… â†’ æ‹†åˆ†ä¸ºä¼šè¯æµ â†’ æå–æ¯ä¸ªæµçš„ç‰¹å¾åºåˆ— â†’ **(Traffic2Graph)** æ„å»ºæµé‡å…³ç³»å›¾TRG â†’ **(Graph Structural Instruction Tuning)** é€šè¿‡è‡ªç›‘ç£ä»»åŠ¡è®©ETooLæ¨¡å‹ç†è§£å›¾ç»“æ„ â†’ **(Traffic-Task Instruction Tuning)**é’ˆå¯¹å…·ä½“åˆ†ç±»ä»»åŠ¡è¿›è¡Œå¾®è°ƒ â†’ è¾“å‡ºæœ€ç»ˆçš„æµé‡ç±»åˆ«ã€‚
- **åˆ›æ–°æ¶æ„ç‰¹ç‚¹:**æœ€å¤§çš„åˆ›æ–°åœ¨äºè®¾è®¡äº†ä¸€ä¸ªä¸¤é˜¶æ®µçš„æŒ‡ä»¤å¾®è°ƒèŒƒå¼ï¼Œå®ƒå·§å¦™åœ°å°†ç»“æ„åŒ–æ•°æ®ï¼ˆæµé‡å›¾ï¼‰çš„é¢†åŸŸçŸ¥è¯†æ³¨å…¥åˆ°ä¸ºæ–‡æœ¬è®¾è®¡çš„LLMä¸­ï¼Œä¸“é—¨ç”¨äºè§£å†³ç½‘ç»œæµé‡é¢†åŸŸçš„O.O.D.é—®é¢˜ã€‚

æ ¹æ®æ‚¨æä¾›çš„è®ºæ–‡ï¼ŒETooLæ¨¡å‹æ˜¯ä¸€ä¸ªä¸“ä¸ºè§£å†³**éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-I.I.D.ï¼‰**åœºæ™¯ä¸‹çš„åŠ å¯†ç½‘ç»œæµé‡åˆ†ç±»é—®é¢˜è€Œè®¾è®¡çš„åˆ›æ–°æ¡†æ¶ã€‚å®ƒçš„å…¨ç§°æ˜¯ **E**ncrypted **T**raffic **O**ut-**o**f-Distribution **I**nstruction **T**uning with **L**LMï¼ˆåŸºäºLLMå’ŒæŒ‡ä»¤å¾®è°ƒçš„åˆ†å¸ƒå¤–åŠ å¯†æµé‡æ¨¡å‹ï¼‰ã€‚

ä»¥ä¸‹æ˜¯å¯¹ETooLæ¨¡å‹çš„è¯¦ç»†è§£é‡Šï¼š

### 1. è§£å†³çš„æ ¸å¿ƒé—®é¢˜

ä¼ ç»Ÿçš„åŠ å¯†æµé‡åˆ†ç±»æ¨¡å‹é€šå¸¸å‡è®¾è®­ç»ƒæ•°æ®å’Œæœªæ¥é‡åˆ°çš„æµ‹è¯•æ•°æ®éµå¾ªç›¸åŒçš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå³ç‹¬ç«‹åŒåˆ†å¸ƒï¼ŒI.I.D.ï¼‰ã€‚ç„¶è€Œï¼Œåœ¨çœŸå®çš„ç½‘ç»œç¯å¢ƒä¸­ï¼Œç”±äºåº”ç”¨ç‰ˆæœ¬æ›´æ–°ã€ç”¨æˆ·è¡Œä¸ºå˜åŒ–æˆ–æ—¶é—´æ¨ç§»ï¼Œç½‘ç»œæµé‡çš„æ¨¡å¼ä¼šä¸æ–­å˜åŒ–ï¼Œå¯¼è‡´æ•°æ®åˆ†å¸ƒå‘ç”Ÿ**æ¼‚ç§»ï¼ˆDistribution Driftï¼‰**ã€‚è¿™ç§æ¼‚ç§»ä½¿å¾—åœ¨æ—§æ•°æ®ä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦ä¸æ–­ç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œè¿™æ—¢è€—æ—¶åˆè€—åŠ›ï¼Œå¹¶ä¸”å¯èƒ½å¯¼è‡´æ¨¡å‹å¿˜è®°æ—§çš„çŸ¥è¯†ã€‚

ETooLçš„ç›®æ ‡å°±æ˜¯è§£å†³è¿™ä¸€éš¾é¢˜ï¼Œæ„å»ºä¸€ä¸ªèƒ½å¤Ÿ**â€œä»¥ä¸å˜åº”ä¸‡å˜â€**çš„æ¨¡å‹ï¼Œä½¿å…¶åœ¨é¢å¯¹åˆ†å¸ƒå˜åŒ–çš„æµé‡æ—¶ï¼Œæ— éœ€é‡æ–°è®­ç»ƒä¹Ÿèƒ½ä¿æŒå¼ºå¤§çš„åˆ†ç±»èƒ½åŠ›å’Œæ³›åŒ–æ€§ã€‚

### 2. ETooLçš„æ ¸å¿ƒæ€æƒ³

ETooLçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œ**å•ä¸ªç½‘ç»œæµçš„ç‰¹å¾ï¼ˆå¦‚åŒ…å¤§å°ã€æ—¶é—´é—´éš”ï¼‰åœ¨åˆ†å¸ƒå˜åŒ–æ—¶å®¹æ˜“å˜å¾—ä¸ç¨³å®šï¼Œä½†å¤šä¸ªç½‘ç»œæµä¹‹é—´çš„äº¤äº’æ¨¡å¼å’Œæ‹“æ‰‘å…³ç³»åˆ™ç›¸å¯¹æ›´ä¸ºç¨³å¥**ã€‚å› æ­¤ï¼ŒETooLä¸ä¾èµ–å•ä¸ªæ•°æ®æµï¼Œè€Œæ˜¯ä¸“æ³¨äºå­¦ä¹ è¿™ç§æ›´é€šç”¨çš„ã€è·¨æµçš„äº¤äº’å…³è”æ¨¡å¼ã€‚å®ƒé€šè¿‡å°†è¿™äº›ç¨³å®šçš„ç»“æ„åŒ–çŸ¥è¯†æ³¨å…¥åˆ°å…·æœ‰å¼ºå¤§æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­ï¼Œæ¥æå‡æ¨¡å‹å¯¹æœªçŸ¥æµé‡åˆ†å¸ƒçš„é€‚åº”æ€§ã€‚

### 3. ETooLçš„å·¥ä½œæµç¨‹ä¸æ ¸å¿ƒç»„ä»¶

ETooLçš„æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡ä¸€ä¸ªä¸¤é˜¶æ®µçš„æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰æµç¨‹æ¥å®ç°ï¼Œå¦‚è®ºæ–‡ä¸­çš„å›¾2æ‰€ç¤ºã€‚

#### **é˜¶æ®µä¸€ï¼šTraffic2Graph (æµé‡åˆ°å›¾çš„è½¬æ¢)**

è¿™æ˜¯æ•°æ®é¢„å¤„ç†é˜¶æ®µï¼Œè´Ÿè´£å°†åŸå§‹çš„ç½‘ç»œæµé‡è½¬åŒ–ä¸ºç»“æ„åŒ–çš„å›¾è¡¨ç¤ºã€‚

- **è¾“å…¥**ï¼šåŸå§‹çš„ç½‘ç»œæµé‡PCAPåŒ…ã€‚
- **è¿‡ç¨‹**ï¼š
    - **èŠ‚ç‚¹ (Node)**ï¼šå›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªç‹¬ç«‹çš„ç½‘ç»œæµï¼ˆç”±æº/ç›®çš„IPã€ç«¯å£å’Œåè®®äº”å…ƒç»„å®šä¹‰ï¼‰ã€‚æ¯ä¸ªèŠ‚ç‚¹åŒ…å«è¯¥æµçš„åŸå§‹æŠ¥æ–‡ï¼ˆRaw Datagramï¼‰åºåˆ—å’Œæœ‰å‘åŒ…é•¿åº¦ï¼ˆPacket Lengthï¼‰åºåˆ—ç­‰ç‰¹å¾ã€‚
    - **è¾¹ (Edge)**ï¼šè¾¹ä»£è¡¨ä¸åŒæµä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œä¸»è¦æœ‰ä¸¤ç§ï¼š
        1. **Burstè¾¹**ï¼šè¿æ¥åœ¨åŒä¸€ä¸ªå¾®å°æ—¶é—´çª—å£å†…å¹¶å‘å»ºç«‹çš„å¤šä¸ªæµï¼Œåæ˜ å®ƒä»¬åœ¨åŠŸèƒ½ä¸Šçš„ååŒå…³ç³»ã€‚
        2. **é‚»æ¥è¾¹**ï¼šè¿æ¥æ—¶é—´ä¸Šå‰åç›¸é‚»çš„ä¸¤ä¸ªâ€œBurstâ€ç»“æ„ï¼Œåæ˜ ä¸šåŠ¡æµç¨‹çš„å»¶ç»­æ€§ã€‚
- **è¾“å‡º**ï¼šä¸€ä¸ªè¢«ç§°ä¸º**æµé‡å…³ç³»å›¾ï¼ˆTraffic Relation Graph, TRGï¼‰**çš„æ•°æ®ç»“æ„ï¼Œå®ƒæ•æ‰äº†å¤šæµä¹‹é—´çš„äº¤äº’æ‹“æ‰‘ã€‚

#### **é˜¶æ®µäºŒï¼šGraph Structural Instruction Tuning (å›¾ç»“æ„æŒ‡ä»¤å¾®è°ƒ)**

è¿™æ˜¯ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ é˜¶æ®µï¼Œå…¶ç›®çš„æ˜¯è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å­¦ä¼š**ç†è§£**æµé‡å›¾çš„ç»“æ„å’Œç‰¹å¾ï¼Œå°†æµé‡é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†æ³¨å…¥LLMã€‚

- **æµé‡å›¾ç¼–ç å¯¹é½**ï¼šæ­¤æ¨¡å—åˆ©ç”¨å¯¹æ¯”å­¦ä¹ çš„æ–¹æ³•ï¼Œå°†å›¾çš„æ‹“æ‰‘ç»“æ„è¡¨ç¤ºå’Œå›¾ä¸­èŠ‚ç‚¹ï¼ˆæµï¼‰çš„ç‰¹å¾è¡¨ç¤ºåœ¨ç¼–ç ç©ºé—´ä¸­è¿›è¡Œå¯¹é½ã€‚è¿™ç¡®ä¿äº†LLMèƒ½å¤Ÿå°†æŠ½è±¡çš„å›¾ç»“æ„ä¸å…·ä½“çš„æµé‡è¡Œä¸ºå…³è”èµ·æ¥ã€‚
- **BURSTå›¾åŒ¹é…ä»»åŠ¡**ï¼šè¿™æ˜¯ä¸€ä¸ªåˆ›æ–°çš„è‡ªç›‘ç£ä»»åŠ¡ã€‚æ¨¡å‹ä¼šæ”¶åˆ°ä¸€ä¸ªæµé‡å­å›¾å’Œä¸€ç»„é¡ºåºè¢«æ‰“ä¹±çš„ã€ä¸è¯¥å­å›¾èŠ‚ç‚¹å¯¹åº”çš„æµé‡ç‰¹å¾ã€‚æ¨¡å‹çš„ä»»åŠ¡æ˜¯æ ¹æ®å›¾çš„æ‹“æ‰‘å…³ç³»ï¼Œå°†è¿™äº›è¢«æ‰“ä¹±çš„ç‰¹å¾é‡æ–°æ’åºï¼Œä½¿å…¶ä¸å›¾ä¸­çš„èŠ‚ç‚¹æ­£ç¡®å¯¹åº”ã€‚é€šè¿‡å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼ŒLLMè¢«è¿«å­¦ä¹ å’Œç†è§£å›¾çš„è¿æ¥å…³ç³»ã€‚

#### **é˜¶æ®µä¸‰ï¼šTraffic-Task Instruction Tuning (æµé‡ä»»åŠ¡æŒ‡ä»¤å¾®è°ƒ)**

åœ¨LLMå…·å¤‡äº†å›¾ç†è§£èƒ½åŠ›åï¼Œæ­¤é˜¶æ®µåˆ©ç”¨æœ‰æ ‡ç­¾çš„æ•°æ®ï¼Œå°†æ¨¡å‹çš„èƒ½åŠ›**é€‚é…**åˆ°æœ€ç»ˆçš„åŠ å¯†æµé‡åˆ†ç±»ä»»åŠ¡ä¸Šã€‚

- **è¿‡ç¨‹**ï¼šæ¨¡å‹æ¥æ”¶åŒ…å«å¾…åˆ†ç±»æµé‡å›¾çš„æŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼šâ€œåˆ†æä»¥ä¸‹æµé‡å›¾ï¼Œå¹¶ç¡®å®šå…¶æ‰€å±çš„åº”ç”¨ç±»åˆ«â€ï¼‰ã€‚
- **é«˜æ•ˆå¾®è°ƒ**ï¼šæ­¤é˜¶æ®µé‡‡ç”¨å‚æ•°å†»ç»“çš„è½»é‡çº§å¾®è°ƒç­–ç•¥ï¼Œåªæ›´æ–°æå°‘æ•°å‚æ•°ï¼ˆå¦‚ä¸€ä¸ªåˆ†ç±»å¤´å’ŒæŠ•å½±å±‚ï¼‰ï¼Œè€ŒLLMå’Œå›¾ç¼–ç å™¨çš„ä¸»ä½“å‚æ•°ä¿æŒä¸å˜ã€‚è¿™æå¤§åœ°æå‡äº†è®­ç»ƒæ•ˆç‡ï¼Œå¹¶ä¿ç•™äº†æ¨¡å‹åœ¨å‰ä¸€é˜¶æ®µå­¦åˆ°çš„é€šç”¨æ³›åŒ–çŸ¥è¯†ã€‚

### 4. ETooLçš„åˆ›æ–°ä¹‹å¤„

- **èŒƒå¼åˆ›æ–°**ï¼šé¦–æ¬¡å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒæŒ‡ä»¤å¾®è°ƒèŒƒå¼å¼•å…¥åˆ°è§£å†³O.O.D.åŠ å¯†æµé‡åˆ†ç±»è¿™ä¸€æå…·æŒ‘æˆ˜æ€§çš„é—®é¢˜ä¸­ã€‚
- **ç‰¹å¾è¡¨ç¤ºåˆ›æ–°**ï¼šæ‘’å¼ƒäº†ä¸ç¨³å®šçš„å•æµç‰¹å¾ï¼Œè½¬è€Œæ„å»ºåŸºäºå¤šæµäº¤äº’çš„æµé‡å…³ç³»å›¾ï¼ˆTRGï¼‰ï¼Œä»è€Œæ•è·æ›´ç¨³å¥çš„æµé‡æ¨¡å¼ã€‚
- **å­¦ä¹ æ–¹æ³•åˆ›æ–°**ï¼šè®¾è®¡äº†ç‹¬ç‰¹çš„è‡ªç›‘ç£â€œBURSTå›¾åŒ¹é…â€ä»»åŠ¡ï¼Œä½¿LLMèƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å’Œç†è§£éæ–‡æœ¬çš„ã€ç»“æ„åŒ–çš„æµé‡å›¾æ•°æ®ã€‚
- **é«˜æ•ˆé€‚åº”**ï¼šé€šè¿‡ä¸¤é˜¶æ®µçš„è½»é‡çº§å¾®è°ƒï¼ŒETooLèƒ½å¤Ÿåœ¨ä¸éœ€å¤§è§„æ¨¡é‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆåœ°é€‚åº”æ–°ä»»åŠ¡å’Œæ–°æ•°æ®åˆ†å¸ƒï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„ç—›ç‚¹ã€‚

#### **4.2 å…³é”®æ­¥éª¤è¯¦ç»†è§£æ**

**æ­¥éª¤1ï¼šTraffic2Graphï¼šæ„å»ºæµé‡å…³ç³»å›¾ (Section V)**

- **ç›®æ ‡ä¸ä½œç”¨ï¼š**ä»åŸå§‹æµé‡ä¸­æ„å»ºä¸€ä¸ªæ—¢å…·åˆ¤åˆ«æ€§åˆå…·é€šç”¨æ€§çš„å›¾ç»“æ„è¡¨ç¤ºï¼ˆTRGï¼‰ï¼Œä»¥æ•æ‰ä¸åŒåº”ç”¨åœ¨æµçº§åˆ«ä¸Šçš„ç¨³å®šåä½œæ¨¡å¼ã€‚
- **è¾“å…¥è¾“å‡ºï¼š**
    - è¾“å…¥ï¼šç‰¹å®šæ—¶é—´æ®µå†…æ•è·çš„ç½‘ç»œæµé›†åˆ S={f1,f2,...,fn}ã€‚
    - è¾“å‡ºï¼šä¸€ä¸ªæµé‡å…³ç³»å›¾ G=(V,E)ã€‚
- æ ¸å¿ƒç®—æ³•æœºåˆ¶ï¼ˆå‚è€ƒç®—æ³•1ï¼‰:
    1. **èŠ‚ç‚¹Vå®šä¹‰ (Flow Extractor):** å›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªç½‘ç»œæµã€‚æ¯ä¸ªèŠ‚ç‚¹åŒ…å«è¯¥æµçš„å¤šç»´åº¦ç‰¹å¾ï¼Œä¸»è¦æ˜¯**åŸå§‹æŠ¥æ–‡åºåˆ—**å’Œ**æœ‰å‘åŒ…å¤§å°åºåˆ—**ã€‚
    2. **è¾¹Eå®šä¹‰ (Flow2Graph):** è¾¹ä»£è¡¨æµä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œåˆ†ä¸ºä¸¤ç§ï¼š
        - **BURSTè¾¹ (Burst Edge):** é¦–å…ˆè¯†åˆ«â€œæµçº§BURSTâ€â€”â€”å³åœ¨ä¸€ä¸ªæå°æ—¶é—´é˜ˆå€¼ Î³å†…å»ºç«‹çš„ä¸€ç»„å¹¶å‘æµã€‚BURSTå†…çš„æ‰€æœ‰æµä¹‹é—´ç”¨BURSTè¾¹è¿æ¥ï¼Œè¡¨ç¤ºå®ƒä»¬çš„åŠŸèƒ½ååŒæ€§ã€‚
        - **é‚»æ¥è¾¹ (Adjacency Edge):**ç”¨äºè¿æ¥æ—¶é—´ä¸Šç›¸é‚»çš„ä¸¤ä¸ªBURSTç»“æ„ï¼Œå…·ä½“æ˜¯å°†å‰ä¸€ä¸ªBURSTçš„æœ€åä¸€æ¡æµä¸åä¸€ä¸ªBURSTçš„ç¬¬ä¸€æ¡å’Œæœ€åä¸€æ¡æµç›¸è¿ï¼Œè¡¨ç¤ºåŠŸèƒ½æµç¨‹çš„å»¶ç»­æ€§ã€‚
- **åˆ›æ–°ç‚¹:**æ”¾å¼ƒäº†ä¸ç¨³å®šçš„å•æµç‰¹å¾ï¼Œè½¬è€Œå¯¹å¤šæµä¹‹é—´çš„æ—¶åºå’Œå¹¶å‘å…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œè¿™ç§äº¤äº’æ¨¡å¼åœ¨åº”ç”¨ç‰ˆæœ¬æ›´æ–°åä»èƒ½ä¿æŒç›¸å¯¹ç¨³å®šï¼Œä¸ºæŠµæŠ—åˆ†å¸ƒæ¼‚ç§»æä¾›äº†åšå®åŸºç¡€ã€‚

**æ­¥éª¤2ï¼šGraph Structural Instruction Tuningï¼šå›¾ç»“æ„æŒ‡ä»¤å¾®è°ƒ (Section VI)**

- **ç›®æ ‡ä¸ä½œç”¨:**åœ¨æ— ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œè®©LLMå­¦ä¼šç†è§£æ­¥éª¤1ä¸­ç”Ÿæˆçš„æµé‡å›¾çš„æ‹“æ‰‘ç»“æ„å’ŒèŠ‚ç‚¹ä¿¡æ¯ï¼Œå°†æµé‡é¢†åŸŸçš„ç»“æ„çŸ¥è¯†æ³¨å…¥LLMã€‚
- **æ ¸å¿ƒç®—æ³•æœºåˆ¶:**
    - **æµé‡å›¾ç¼–ç å¯¹é½ (Traffic Graph Encoding Alignment):**
        - **å·¥ä½œåŸç†ï¼š** é‡‡ç”¨ç±»ä¼¼CLIPçš„å¯¹æ¯”å­¦ä¹ æ€æƒ³ã€‚ä½¿ç”¨ä¸€ä¸ªå›¾ç¼–ç å™¨ï¼ˆå¦‚Graph Transformerï¼‰æå–å›¾çš„ç»“æ„ä¿¡æ¯ Hï¼ŒåŒæ—¶ä½¿ç”¨ä¸€ä¸ªæµç¼–ç å™¨ï¼ˆå¦‚ET-BERTï¼‰æå–èŠ‚ç‚¹ï¼ˆæµï¼‰çš„å†…å®¹ç‰¹å¾ Nã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œå°†ä¸¤ç§è¡¨ç¤ºåœ¨ç¼–ç ç©ºé—´ä¸­å¯¹é½ã€‚
        - **æ•°å­¦å…¬å¼è§£è¯»:**å…¬å¼(3)å’Œ(4)å®šä¹‰äº†å¯¹æ¯”å­¦ä¹ çš„ç›¸ä¼¼åº¦è®¡ç®—å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œç›®æ ‡æ˜¯è®©åŒ¹é…çš„å›¾ç»“æ„è¡¨ç¤ºå’Œæµç‰¹å¾è¡¨ç¤ºåœ¨å‘é‡ç©ºé—´ä¸­æ›´æ¥è¿‘ï¼Œä¸åŒ¹é…çš„åˆ™ç›¸äº’è¿œç¦»ã€‚
    - **BURSTå›¾åŒ¹é… (Burst Graph Matching):**
        - **å·¥ä½œåŸç†:**è¿™æ˜¯ä¸€ä¸ªå·§å¦™çš„è‡ªç›‘ç£ä»»åŠ¡ã€‚ç³»ç»Ÿä¼šä»ä¸€ä¸ªå¤§å›¾ä¸­éšæœºé‡‡æ ·ä¸€ä¸ªå­å›¾ï¼Œå¹¶å°†è¯¥å­å›¾åŒ…å«çš„èŠ‚ç‚¹ï¼ˆæµï¼‰ç‰¹å¾é¡ºåºæ‰“ä¹±ã€‚ç„¶åç”Ÿæˆä¸€æ¡æŒ‡ä»¤ï¼Œè¦æ±‚LLMæ ¹æ®ç»™å®šçš„å›¾ç»“æ„ï¼Œå°†æ‰“ä¹±çš„æµç‰¹å¾é‡æ–°æ’åºä¸ºæ­£ç¡®çš„é¡ºåºã€‚
        - **æŠ€æœ¯å®ç°ç»†èŠ‚:**ä¸ºäº†å®Œæˆè¿™ä¸ªä»»åŠ¡ï¼ŒLLMå¿…é¡»ç†è§£å›¾çš„æ‹“æ‰‘å…³ç³»ï¼ˆè°å’Œè°ç›¸é‚»ï¼‰ï¼Œæ‰èƒ½æ­£ç¡®åœ°å°†ç‰¹å¾ä¸èŠ‚ç‚¹å¯¹åº”èµ·æ¥ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯è½»é‡çº§çš„ï¼Œåªè®­ç»ƒä¸€ä¸ªè¿æ¥å›¾ç¼–ç å™¨å’ŒLLMçš„æŠ•å½±å±‚ï¼ˆProjectorï¼‰ï¼Œè€ŒLLMå’Œå›¾ç¼–ç å™¨æœ¬èº«å‚æ•°è¢«å†»ç»“ï¼Œæå¤§æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚
- **åˆ›æ–°ç‚¹:**è®¾è®¡äº†ä¸€ç§ä¸“ä¸ºç½‘ç»œæµé‡å›¾å®šåˆ¶çš„è‡ªç›‘ç£æŒ‡ä»¤å¾®è°ƒä»»åŠ¡ï¼ˆBURSTå›¾åŒ¹é…ï¼‰ï¼Œé«˜æ•ˆåœ°å°†ç»“æ„åŒ–å›¾çŸ¥è¯†è¿ç§»åˆ°LLMä¸­ã€‚

**æ­¥éª¤3ï¼šTraffic-Task Instruction Tuningï¼šæµé‡ä»»åŠ¡æŒ‡ä»¤å¾®è°ƒ (Section VII)**

- **ç›®æ ‡ä¸ä½œç”¨:**å°†å·²ç»å…·å¤‡å›¾ç†è§£èƒ½åŠ›çš„LLMï¼Œè¿›ä¸€æ­¥é€‚é…åˆ°æœ€ç»ˆçš„åŠ å¯†æµé‡åˆ†ç±»ä»»åŠ¡ä¸Šã€‚
- **è¾“å…¥è¾“å‡º:**
    - è¾“å…¥ï¼šå¸¦æœ‰æ ‡ç­¾çš„è®­ç»ƒæ•°æ® (X,y)ï¼Œå…¶ä¸­ Xæ˜¯æµé‡å›¾ã€‚
    - è¾“å‡ºï¼šé¢„æµ‹çš„æµé‡ç±»åˆ«æ ‡ç­¾ yã€‚
- **æ ¸å¿ƒç®—æ³•æœºåˆ¶:**
    - **å·¥ä½œåŸç†:** ä½¿ç”¨åŒ…å«å¾…åˆ†ç±»æµé‡å›¾å’Œé—®é¢˜æè¿°çš„æŒ‡ä»¤æ¨¡æ¿æ¥æŸ¥è¯¢æ¨¡å‹ã€‚ä¾‹å¦‚ï¼šâ€œç»™å®šä»¥ä¸‹æµé‡å›¾<graph>ï¼Œè¯·ç¡®å®šå®ƒå±äºå“ªä¸ªåº”ç”¨ç±»åˆ«ï¼Ÿâ€
    - **æŠ€æœ¯å®ç°ç»†èŠ‚:**æ­¤é˜¶æ®µåŒæ ·å†»ç»“LLMå’Œå›¾ç¼–ç å™¨çš„ä¸»ä½“å‚æ•°ï¼Œä»…å¾®è°ƒåœ¨ä¸Šä¸€é˜¶æ®µè®­ç»ƒå¥½çš„æŠ•å½±å±‚å’Œä¸€ä¸ªæ–°æ·»åŠ çš„è½»é‡çº§åˆ†ç±»å¤´ã€‚è¿™ä¿è¯äº†æ¨¡å‹åœ¨å­¦ä¹ æ–°ä»»åŠ¡æ—¶ä¸ä¼šä¸¢å¤±å·²æœ‰çš„æ³›åŒ–çŸ¥è¯†ã€‚
- **åˆ›æ–°ç‚¹:** å®ç°äº†ä»¥æå°çš„è®­ç»ƒä»£ä»·å°†å¼ºå¤§çš„é€šç”¨æ¨¡å‹é€‚é…åˆ°ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶ä¿æŒäº†å…¶åœ¨O.O.D.åœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚

#### **4.3 æ ¸å¿ƒæŠ€æœ¯æ·±åº¦åˆ†æ**

- **4.3.1 å­¦ç§‘å½’å±ä¸ç†è®ºåŸºç¡€:**
    - **ä¸»è¦å­¦ç§‘é¢†åŸŸ:** ç½‘ç»œå®‰å…¨ã€æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€‚
    - **äº¤å‰å­¦ç§‘è¯†åˆ«:** æ·±åº¦å­¦ä¹ ï¼ˆç‰¹åˆ«æ˜¯Transformeræ¶æ„ï¼‰ã€å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ã€è¡¨å¾å­¦ä¹ ã€è¿ç§»å­¦ä¹ ã€‚
    - **ç†è®ºåŸºç¡€è„‰ç»œ:æ–¹æ³•çš„æ ¹åŸºåœ¨äº**è¡¨å¾å­¦ä¹ ï¼Œå³å­¦ä¹ ä¸€ç§èƒ½å¤ŸæŠµæŠ—åˆ†å¸ƒå˜åŒ–çš„ç¨³å¥æ•°æ®è¡¨ç¤ºã€‚å®ƒå€Ÿé‰´äº†**å›¾è®º**æ¥å¯¹å¤šæµå…³ç³»è¿›è¡Œå»ºæ¨¡ï¼Œåˆ©ç”¨äº†**Transformeræ¶æ„**ï¼ˆLLMå’Œå›¾ç¼–ç å™¨çš„åŸºç¡€ï¼‰å¼ºå¤§çš„åºåˆ—å’Œç»“æ„å»ºæ¨¡èƒ½åŠ›ï¼Œå¹¶é‡‡ç”¨äº†**è¿ç§»å­¦ä¹ **ä¸­çš„æŒ‡ä»¤å¾®è°ƒèŒƒå¼æ¥å®ç°çŸ¥è¯†çš„æœ‰æ•ˆè¿ç§»ã€‚
- **4.3.2 æ ¸å¿ƒç®—æ³•è¯¦è§£:**
    - **LLM (Vicuna-7B-v1.5):**ä½œä¸ºæ–¹æ³•çš„å¤§è„‘ï¼Œå…¶ç†è®ºåŸºç¡€æ˜¯Transformeræ¶æ„ã€‚å®ƒé€šè¿‡è‡ªæ³¨æ„åŠ›æœºåˆ¶æ•æ‰é•¿è·ç¦»ä¾èµ–ï¼Œå¹¶é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒè·å¾—äº†å¼ºå¤§çš„ä¸Šä¸‹æ–‡ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œè¿™æ˜¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„æ ¸å¿ƒæ¥æºã€‚
    - **å¯¹æ¯”å­¦ä¹ :** å…¶ç†è®ºåŸºç¡€æ˜¯æœ€å¤§åŒ–åŒç±»æ ·æœ¬çš„ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–å¼‚ç±»æ ·æœ¬çš„ç›¸ä¼¼åº¦ã€‚åœ¨è¿™é‡Œç”¨äºå¯¹é½å›¾çš„ç»“æ„è¯­ä¹‰å’ŒèŠ‚ç‚¹çš„å†…å®¹è¯­ä¹‰ï¼Œç¡®ä¿LLMèƒ½å°†æ‹“æ‰‘å…³ç³»ä¸å®é™…çš„æµé‡è¡Œä¸ºè”ç³»èµ·æ¥ã€‚
- **4.3.3 å…³é”®æ•°æ®ç»“æ„ä¸è¡¨ç¤º:**
    - **æµé‡å…³ç³»å›¾ (TRG):** æœ€æ ¸å¿ƒçš„æ•°æ®ç»“æ„ã€‚å®ƒå°†éç»“æ„åŒ–çš„æ—¶åºæµé‡æ•°æ®è½¬åŒ–ä¸ºç»“æ„åŒ–çš„å›¾æ•°æ®ï¼Œå…¶èŠ‚ç‚¹åŒ…å«å¤šæ¨¡æ€ç‰¹å¾ï¼ˆæŠ¥æ–‡ã€åŒ…é•¿ï¼‰ï¼Œè¾¹åˆ™ç¼–ç äº†æ—¶åºå’Œå¹¶å‘å…³ç³»ã€‚è¿™ç§ç»“æ„åŒ–è¡¨ç¤ºæ¯”åŸå§‹åºåˆ—æ›´èƒ½æ•æ‰åˆ°ç¨³å®šçš„é«˜é˜¶äº¤äº’ä¿¡æ¯ã€‚
- **4.3.4 ä¼˜åŒ–ç­–ç•¥åˆ†æ:**
    - **å‚æ•°å†»ç»“å¾®è°ƒ (Parameter-Efficient Fine-Tuning, PEFT):**åœ¨ä¸¤ä¸ªå¾®è°ƒé˜¶æ®µéƒ½å†»ç»“äº†LLMå’Œå›¾ç¼–ç å™¨çš„å¤§éƒ¨åˆ†å‚æ•°ï¼Œåªè®­ç»ƒæå°‘æ•°çš„è¿æ¥å±‚/æŠ•å½±å±‚ã€‚è¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„ä¼˜åŒ–ç­–ç•¥ï¼Œæå¤§åœ°é™ä½äº†è®¡ç®—èµ„æºéœ€æ±‚å’Œè®­ç»ƒæ—¶é—´ï¼ŒåŒæ—¶æœ‰æ•ˆé˜²æ­¢äº†ç¾éš¾æ€§é—å¿˜ã€‚
- **4.3.5 é²æ£’æ€§è®¾è®¡:**
    - æ–¹æ³•çš„æ ¸å¿ƒè®¾è®¡â€”â€”åŸºäºå¤šæµäº¤äº’å›¾è€Œéå•æµç‰¹å¾ï¼Œæœ¬èº«å°±æ˜¯ä¸ºäº†æå‡å¯¹åˆ†å¸ƒæ¼‚ç§»çš„é²æ£’æ€§ã€‚å› ä¸ºåº”ç”¨çš„åŠŸèƒ½é€»è¾‘ï¼ˆä½“ç°åœ¨å¤šæµåä½œä¸Šï¼‰é€šå¸¸æ¯”å…·ä½“çš„æµé‡ç‰¹å¾ï¼ˆå¦‚åŒ…å¤§å°ã€æ—¶é—´é—´éš”ï¼‰æ›´ç¨³å®šã€‚
    - LLMçš„å¼•å…¥ï¼Œåˆ©ç”¨å…¶ä»æµ·é‡æ•°æ®ä¸­å­¦åˆ°çš„é€šç”¨æ¨ç†èƒ½åŠ›ï¼Œå¸®åŠ©æ¨¡å‹åœ¨é¢å¯¹æœªè§è¿‡çš„æµé‡æ¨¡å¼æ—¶ï¼Œèƒ½å¤Ÿè¿›è¡Œâ€œä¸¾ä¸€åä¸‰â€çš„æ¨æ–­ï¼Œè€Œä¸æ˜¯ç®€å•åœ°æ¨¡å¼åŒ¹é…ã€‚

#### **4.4 æ–¹æ³•é›†æˆåˆ†æ**

- **æ¨¡å—ååŒæœºåˆ¶:** Traffic2Graphæ¨¡å—æ˜¯æ•°æ®é¢„å¤„ç†å™¨ï¼Œä¸ºåç»­çš„LLMåˆ†ææä¾›é«˜è´¨é‡çš„ç»“æ„åŒ–è¾“å…¥ã€‚ä¸¤ä¸ªæŒ‡ä»¤å¾®è°ƒé˜¶æ®µåˆ™æ˜¯ä¸€ä¸ªé€’è¿›çš„è¿‡ç¨‹ï¼šç¬¬ä¸€é˜¶æ®µæ•™ä¼šLLMâ€œçœ‹æ‡‚â€å›¾ï¼Œæ˜¯åŸºç¡€èƒ½åŠ›å»ºè®¾ï¼›ç¬¬äºŒé˜¶æ®µåˆ™æ˜¯åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæ•™ä¼šLLMâ€œåˆ©ç”¨â€å›¾æ¥å®Œæˆç‰¹å®šä»»åŠ¡ï¼Œæ˜¯ä¸“ä¸šèƒ½åŠ›è®­ç»ƒã€‚ä¸‰è€…ç¯ç¯ç›¸æ‰£ï¼Œç¼ºä¸€ä¸å¯ã€‚
- **ç«¯åˆ°ç«¯å¤„ç†æµç¨‹:** ä»åŸå§‹æµé‡è¾“å…¥å¼€å§‹ï¼Œç»è¿‡å›¾æ„å»ºã€ç¼–ç å¯¹é½ã€è‡ªç›‘ç£ç»“æ„å­¦ä¹ ï¼Œæœ€ç»ˆåˆ°æœ‰ç›‘ç£ä»»åŠ¡å­¦ä¹ ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆã€‚
- **å…³é”®å†³ç­–é€»è¾‘:** æ•´ä¸ªæ–¹æ³•çš„æ ¸å¿ƒå†³ç­–åœ¨äºç›¸ä¿¡â€œæµé—´çš„äº¤äº’ç»“æ„æ˜¯æ¯”æµæœ¬èº«æ›´ç¨³å®šçš„ç‰¹å¾â€ï¼Œå¹¶é€‰æ‹©LLMä½œä¸ºå­¦ä¹ å’Œåˆ©ç”¨è¿™ç§ç¨³å®šç»“æ„çš„æœ€ä½³è½½ä½“ã€‚

---

### **5. å®éªŒåˆ†æ**

ç”±**å®éªŒåˆ†æä¸“å®¶**ç³»ç»Ÿæ€§è¯„ä¼°è®ºæ–‡çš„å®éªŒè®¾è®¡å’Œç»“æœï¼š

#### **5.1 å®éªŒç¯å¢ƒè®¾ç½®**

- **æ•°æ®é›†:**
    - APP53: ä¸€ä¸ªå…¬å¼€æ•°æ®é›†ï¼ŒåŒ…å«ä¸åŒæ—¶é—´ã€ä¸åŒåº”ç”¨ç‰ˆæœ¬çš„æµé‡ï¼Œç”¨äºæ„å»ºI.I.D.å’ŒO.O.D.ï¼ˆæ—¶é—´æ¼‚ç§»å’Œç‰ˆæœ¬æ¼‚ç§»ï¼‰åœºæ™¯ã€‚
    - ISCX-Botnet: ç”¨äºæ¶æ„æœåŠ¡åˆ†ç±»ä»»åŠ¡ï¼Œé€šè¿‡è®­ç»ƒé›†ä¸­ä¸åŒ…å«æ‰€æœ‰æ¶æ„è½¯ä»¶ç±»å‹æ¥æ¨¡æ‹ŸO.O.D.åœºæ™¯ã€‚
    - **NETD:**ä½œè€…æ–°å»ºçš„æ•°æ®é›†ï¼ŒåŸºäºISCX-VPNæ„å»ºï¼Œæ”¯æŒé€šè¿‡è°ƒæ•´â€œæ¯”ä¾‹åå·®â€å’Œâ€œæˆåˆ†åå·®â€æ¥åŠ¨æ€æ§åˆ¶O.O.D.çš„ç¨‹åº¦ï¼Œæ˜¯éªŒè¯æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å…³é”®ã€‚
- **è¯„ä¼°æŒ‡æ ‡:**å‡†ç¡®ç‡(Accuracy), ç²¾ç¡®ç‡(Precision), å¬å›ç‡(Recall), F1åˆ†æ•°(F1-Score)ï¼Œå‡é‡‡ç”¨å®å¹³å‡ï¼ˆMacro Averageï¼‰ä»¥åº”å¯¹ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚
- **åŸºçº¿æ–¹æ³•:**è¦†ç›–äº†ä¸‰ç±»ä¸»æµæŠ€æœ¯ï¼š(1) ç»Ÿè®¡ç‰¹å¾æ–¹æ³• (AppScanner, CUMUL)ï¼›(2) æ·±åº¦å­¦ä¹ æ–¹æ³• (DF, FS-Net, GraphDApp)ï¼›(3) é¢„è®­ç»ƒæ–¹æ³• (PERT, ET-BERT)ã€‚
- **å®éªŒå¹³å°:**ä½¿ç”¨ Vicuna-7B-v1.5 ä½œä¸ºåŸºç¡€LLMï¼Œåœ¨NVIDIA Tesla A800 80GB GPUsä¸Šç”¨PyTorchå®ç°ã€‚

#### **5.2 å®éªŒè¯¦ç»†åˆ†æ**

**å®éªŒ1: æ€»ä½“æ€§èƒ½å¯¹æ¯” (RQ1)**

- **å®éªŒè®¾è®¡çš„ç†ç”±ï¼š**éªŒè¯ETooLåœ¨ç†æƒ³çš„I.I.D.åœºæ™¯å’Œæ›´å…·æŒ‘æˆ˜æ€§çš„O.O.D.ï¼ˆé›¶æ ·æœ¬ï¼‰åœºæ™¯ä¸‹ï¼Œç›¸è¾ƒäºç°æœ‰SOTAæ–¹æ³•çš„æ€§èƒ½ä¼˜åŠ¿ã€‚
- **å®éªŒç»“æœï¼š**
    - **I.I.D.åœºæ™¯:**ETooLè¡¨ç°æœ€ä½³ï¼Œåœ¨APP53-TIMEä»»åŠ¡ä¸ŠF1åˆ†æ•°è¾¾åˆ°93.19%ï¼Œæ¯”å¼ºå¤§çš„åŸºçº¿ET-BERTé«˜å‡º6.62%ã€‚
    - **O.O.D.åœºæ™¯:**ETooLçš„ä¼˜åŠ¿æä¸ºæ˜¾è‘—ã€‚åœ¨APP53æ—¶é—´æ¼‚ç§»ä»»åŠ¡ä¸­ï¼Œå½“å…¶ä»–æ–¹æ³•æ€§èƒ½å¤§å¹…ä¸‹é™ï¼ˆå¦‚ET-BERTé™è‡³56.71%ï¼‰æ—¶ï¼ŒETooLä»ä¿æŒäº†74.88%çš„F1åˆ†æ•°ã€‚åœ¨æ›´éš¾çš„ç‰ˆæœ¬æ¼‚ç§»ä»»åŠ¡ä¸­ï¼ŒETooLçš„F1åˆ†æ•°ä¸º72.13%ï¼Œè¿œè¶…æ‰€æœ‰åŸºçº¿ã€‚åœ¨ISCX-Botnetæ¶æ„æµé‡æ£€æµ‹ä¸­ï¼ŒETooLçš„F1åˆ†æ•°æ¯”æœ€ä½³åŸºçº¿é«˜å‡º9.16%ï¼ˆäºŒåˆ†ç±»ï¼‰å’Œ12.08%ï¼ˆå¤šåˆ†ç±»ï¼‰ã€‚
- **å¯¹åº”å›¾è¡¨ï¼š**è¡¨IVå’Œ è¡¨Vè¯¦ç»†å±•ç¤ºäº†åœ¨APP53å’ŒISCX-Botnetæ•°æ®é›†ä¸Šçš„å…¨é¢å¯¹æ¯”ç»“æœã€‚

**å®éªŒ2: æ¶ˆèç ”ç©¶ (RQ2)**

- **å®éªŒè®¾è®¡çš„ç†ç”±ï¼š**æ¢ç©¶ETooLæ¡†æ¶ä¸­å„ä¸ªå…³é”®ç»„ä»¶ï¼ˆå¦‚ä¸åŒç²’åº¦çš„è¾“å…¥ç‰¹å¾ã€å›¾ç»“æ„å¾®è°ƒã€LLMæœ¬èº«ï¼‰å¯¹æ•´ä½“æ€§èƒ½çš„è´¡çŒ®ç¨‹åº¦ã€‚
- **å®éªŒç»“æœï¼š**
    - ç§»é™¤å›¾ç»“æ„å’Œå›¾æŒ‡ä»¤å¾®è°ƒï¼ˆw/o Graph Structural Tuningï¼‰å¯¼è‡´æ€§èƒ½ä¸‹é™æœ€ä¸¥é‡ï¼ŒF1åˆ†æ•°å¹³å‡é™ä½äº†22.13%ã€‚
    - ç§»é™¤LLMï¼Œç”¨æ™®é€šçš„Graph Transformerä»£æ›¿ï¼ˆw/o Large Language Modelï¼‰ï¼ŒF1åˆ†æ•°ä¹Ÿå¹³å‡ä¸‹é™äº†12.84%ã€‚
    - ç§»é™¤åŸå§‹æŠ¥æ–‡æˆ–åŒ…é•¿åº¦åºåˆ—ç­‰è¾“å…¥ç‰¹å¾ä¹Ÿä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
    - **ç»“è®ºï¼š** æµé‡å›¾çš„ç»“æ„åŒ–è¡¨ç¤ºå’ŒåŸºäºLLMçš„æŒ‡ä»¤å¾®è°ƒèŒƒå¼æ˜¯ETooLæˆåŠŸçš„ä¸¤ä¸ªæœ€å…³é”®å› ç´ ã€‚
- **å¯¹åº”å›¾è¡¨ï¼š**è¡¨VIæ¸…æ™°åœ°åˆ—å‡ºäº†ç§»é™¤ä¸åŒæ¨¡å—åçš„æ€§èƒ½æ•°æ®ã€‚

**å®éªŒ3: åŠ¨æ€åˆ†å¸ƒæ³›åŒ–èƒ½åŠ›ç ”ç©¶ (RQ3)**

- **å®éªŒè®¾è®¡çš„ç†ç”±ï¼š**åœ¨ä¸“é—¨æ„å»ºçš„ã€å¯æ§åˆ†å¸ƒå˜åŒ–çš„NETDæ•°æ®é›†ä¸Šï¼Œè¿›ä¸€æ­¥æ£€éªŒETooLå¤„ç†ä¸åŒç±»å‹å’Œç¨‹åº¦çš„O.O.D.é—®é¢˜çš„é²æ£’æ€§ã€‚
- **å®éªŒç»“æœï¼š**åœ¨NETD-1åˆ°NETD-4å››ä¸ªå…·æœ‰ä¸åŒåˆ†å¸ƒåå·®è®¾ç½®çš„æ•°æ®é›†ä¸Šï¼ŒETooLçš„åˆ†ç±»æ€§èƒ½ï¼ˆæŸ±çŠ¶å›¾ï¼‰å§‹ç»ˆæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ã€‚è™½ç„¶åœ¨I.I.D.åŸºå‡†ä¸Šï¼ˆæŠ˜çº¿ï¼‰ä¸ET-BERTè¡¨ç°æ¥è¿‘ï¼Œä½†åœ¨å¼•å…¥åˆ†å¸ƒæ¼‚ç§»åï¼ŒETooLå±•ç°äº†è¿œè¶…å¯¹æ‰‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚
- **å¯¹åº”å›¾è¡¨ï¼š**å›¾4ç›´è§‚åœ°å±•ç¤ºäº†ETooLåœ¨å››ä¸ªåŠ¨æ€Non-I.I.D.æ•°æ®é›†ä¸Šçš„å“è¶Šè¡¨ç°ã€‚

**å®éªŒ4: æ¨¡å‹æ•ˆç‡ç ”ç©¶ (RQ4)**

- **å®éªŒè®¾è®¡çš„ç†ç”±ï¼š**è¯„ä¼°æ‰€æå‡ºçš„å‚æ•°å†»ç»“å¾®è°ƒç­–ç•¥åœ¨è®­ç»ƒæ—¶é—´ã€ç©ºé—´å¼€é”€ä¸Šçš„æ•ˆç‡ã€‚
- **å®éªŒç»“æœï¼š**å‚æ•°å†»ç»“ç­–ç•¥æä¸ºé«˜æ•ˆã€‚ä¸å…¨å‚æ•°å¾®è°ƒï¼ˆä¼šå¯¼è‡´æ˜¾å­˜æº¢å‡ºOOMï¼‰ç›¸æ¯”ï¼Œè¯¥ç­–ç•¥å°†éœ€è®­ç»ƒçš„å‚æ•°é‡å‡å°‘äº†è¶…è¿‡50å€ï¼Œå¤§å¹…ç¼©çŸ­äº†è®­ç»ƒæ—¶é—´å¹¶é™ä½äº†ç¡¬ä»¶è¦æ±‚ã€‚è™½ç„¶æ¨ç†å»¶è¿Ÿå°šä¸èƒ½æ»¡è¶³å®æ—¶æ£€æµ‹ï¼Œä½†éå¸¸é€‚åˆéœ€è¦é«˜å‡†ç¡®åº¦çš„ç¦»çº¿åˆ†ææˆ–è¾…åŠ©å†³ç­–åœºæ™¯ã€‚
- **å¯¹åº”å›¾è¡¨ï¼š**è¡¨VIIè¯¦ç»†å¯¹æ¯”äº†å†»ç»“ä¸å…¨å‚æ•°å¾®è°ƒåœ¨è®­ç»ƒæ—¶é—´ã€å‚æ•°é‡ã€GPUå ç”¨ç­‰æ–¹é¢çš„å·¨å¤§å·®å¼‚ã€‚

**å®éªŒ5: è¶…å‚æ•°å½±å“åˆ†æ (RQ5)**

- **å®éªŒè®¾è®¡çš„ç†ç”±ï¼š**åˆ†æå…³é”®è¶…å‚æ•°ï¼ˆBURSTæ—¶é—´é˜ˆå€¼ã€å­¦ä¹ ç‡ï¼‰çš„é€‰æ‹©å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚
- **å®éªŒç»“æœï¼š**å®éªŒè¡¨æ˜ï¼ŒBURSTæ—¶é—´é˜ˆå€¼è®¾ä¸º1ç§’å·¦å³æ•ˆæœæœ€ä½³ã€‚å­¦ä¹ ç‡è®¾ä¸º 2Ã—eâˆ’3æ—¶æ¨¡å‹è¡¨ç°æœ€å¥½ã€‚è¿™è¯´æ˜åˆç†çš„è¶…å‚æ•°è®¾ç½®å¯¹å‘æŒ¥æ¨¡å‹æ½œåŠ›è‡³å…³é‡è¦ã€‚
- **å¯¹åº”å›¾è¡¨ï¼š**å›¾5 å±•ç¤ºäº†ä¸åŒè¶…å‚æ•°è®¾ç½®ä¸‹çš„æ¨¡å‹æ€§èƒ½æ›²çº¿ã€‚

</details>

## ğŸ¤ è´¡çŒ®ä»£ç 

æ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ï¼å¼€æºç¤¾åŒºå› æ‚¨çš„æ¯ä¸€æ¬¡è´¡çŒ®è€Œæ›´åŠ ç²¾å½©ã€‚æ‚¨å¯ä»¥ï¼š
*   Fork æœ¬é¡¹ç›®
*   åˆ›å»ºæ‚¨çš„åŠŸèƒ½åˆ†æ”¯
*   æäº¤æ‚¨çš„æ›´æ”¹
*   å‘èµ·ä¸€ä¸ª Pull Request
*   æˆ–è€…ï¼Œæäº¤ Bug å’Œå»ºè®®ã€‚

## ğŸŒŸ æœªæ¥å±•æœ› & DeepRead æœºå™¨äºº

`DeepRead-Agent-Prompt` æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åŸºç¡€ã€‚æˆ‘ä»¬çš„æ„¿æ™¯æ˜¯å°†å…¶å‘å±•æˆä¸€ä¸ªæ›´å¼ºå¤§ã€æ›´æ˜“äºä½¿ç”¨çš„å·¥å…·ã€‚

**ä¸ºäº†æä¾›æ›´ä¾¿æ·çš„ä¸€é”®å¼ä½“éªŒï¼Œæˆ‘ä»¬æ­£åœ¨å¼€å‘ DeepRead æœºå™¨äººã€‚** å¹¶æä¾›å¦‚ä¸‹é«˜çº§åŠŸèƒ½ï¼š
*   **ç›´æ¥ä¸Šä¼  PDF/URL**ï¼šæ— éœ€å†æ‰‹åŠ¨å¤åˆ¶ç²˜è´´æ–‡æœ¬ã€‚
*   **äº¤äº’å¼åˆ†æ**ï¼šå¯é’ˆå¯¹ç”Ÿæˆçš„æŠ¥å‘Šè¿›è¡Œè¿½é—®ã€‚
*   **çŸ¥è¯†åº“é›†æˆ**ï¼šè‡ªåŠ¨ä¿å­˜å’Œç´¢å¼•æ‚¨åˆ†æè¿‡çš„è®ºæ–‡ã€‚
*   **æŒç»­ä¼˜åŒ–**ï¼šæœºå™¨äººå°†å§‹ç»ˆè¿è¡Œåœ¨æœ€æ–°ã€æœ€å¼ºå¤§çš„æç¤ºè¯ç‰ˆæœ¬ä¸Šã€‚

æ•¬è¯·æœŸå¾…ï¼æ‚¨å¯¹è¿™ä¸ªå¼€æºé¡¹ç›®çš„æ”¯æŒï¼Œå°†åŠ é€Ÿè¿™äº›é«˜çº§åŠŸèƒ½çš„å¼€å‘ã€‚

## ğŸ“œ å¼€æºè®¸å¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯åè®®ã€‚è¯¦æƒ…è¯·è§ `LICENSE` æ–‡ä»¶ã€‚

## ğŸ“§ è”ç³»æ–¹å¼

é¡¹ç›®é“¾æ¥: [https://github.com/li4oya/DeepRead-Agent-Prompt](https://github.com/li4oya/DeepRead-Agent-Prompt)

</details>
